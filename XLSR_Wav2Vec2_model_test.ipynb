{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab_jamos.json\",\n",
    "                                 unk_token=\"[UNK]\",\n",
    "                                 pad_token=\"[PAD]\",\n",
    "                                 word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1,\n",
    "                                             sampling_rate=16000,\n",
    "                                             padding_value=0.0,\n",
    "                                             do_normalize=True,\n",
    "                                             return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor,\n",
    "                              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \".\\service_1\\Assets\\jamo_base_model\",\n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66976,)\n",
      "-0.12826538 0.11135864\n"
     ]
    }
   ],
   "source": [
    "array,_ = librosa.load('./service_1/Assets/test_data_1.wav',16000)\n",
    "print(array.shape)\n",
    "print(array.min(), array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66976,)\n",
      "-7.489833 6.522962\n"
     ]
    }
   ],
   "source": [
    "array = processor(array, sampling_rate=16000).input_values[0]\n",
    "print(array.shape)\n",
    "print(array.min(), array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(torch.from_numpy(array.reshape(1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_decode(pred):\n",
    "    pred_logits = pred['logits'].detach().numpy()\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    return pred_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅂㅗ<pad> ㅇ<pad>ㅣㅆㄴ<pad>ㅡ<pad>ㄴ ㅇ<pad>ㅕㅇ<pad>ㅅ<pad>ㅏ<pad>ㅇ<pad> ㅈ<pad>ㅓ<pad>ㅇ<pad>ㅈ<pad>ㅣ<pad>ㅅ<pad>ㅣ<pad>ㅋ<pad>ㅕ<pad> ㅈㅝ\n"
     ]
    }
   ],
   "source": [
    "pred_str = ''.join(pred_decode(pred))\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅂㅗ ㅇㅣㅆㄴㅡㄴ ㅇㅕㅇㅅㅏㅇ ㅈㅓㅇㅈㅣㅅㅣㅋㅕ ㅈㅝ\n"
     ]
    }
   ],
   "source": [
    "remove_pad_token = re.sub('<pad>','',pred_str)\n",
    "print(remove_pad_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mu-jun\\anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:578: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "c:\\Users\\Mu-jun\\anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:617: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = torch.randn(1,100000,requires_grad=True)\n",
    "print(x.dtype)\n",
    "\n",
    "torch.onnx.export(model,\n",
    "                  x,\n",
    "                  \"./outputs/jamo_base_model.onnx\",\n",
    "                  input_names=[\"input\"],\n",
    "                  output_names=[\"output\"],\n",
    "                  dynamic_axes={\n",
    "                      \"input\":{\n",
    "                          0: \"batch\",\n",
    "                          1: \"time\",\n",
    "                      },\n",
    "                      \"output\":{\n",
    "                          0: \"batch\",\n",
    "                          1: \"seqeunce\",\n",
    "                      }\n",
    "                  },\n",
    "                  opset_version=11,\n",
    "                  do_constant_folding=True,\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "import onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ignore MatMul due to non constant B: /[MatMul_236]\n",
      "Ignore MatMul due to non constant B: /[MatMul_238]\n",
      "Ignore MatMul due to non constant B: /[MatMul_325]\n",
      "Ignore MatMul due to non constant B: /[MatMul_327]\n",
      "Ignore MatMul due to non constant B: /[MatMul_414]\n",
      "Ignore MatMul due to non constant B: /[MatMul_416]\n",
      "Ignore MatMul due to non constant B: /[MatMul_503]\n",
      "Ignore MatMul due to non constant B: /[MatMul_505]\n",
      "Ignore MatMul due to non constant B: /[MatMul_592]\n",
      "Ignore MatMul due to non constant B: /[MatMul_594]\n",
      "Ignore MatMul due to non constant B: /[MatMul_681]\n",
      "Ignore MatMul due to non constant B: /[MatMul_683]\n",
      "Ignore MatMul due to non constant B: /[MatMul_770]\n",
      "Ignore MatMul due to non constant B: /[MatMul_772]\n",
      "Ignore MatMul due to non constant B: /[MatMul_859]\n",
      "Ignore MatMul due to non constant B: /[MatMul_861]\n",
      "Ignore MatMul due to non constant B: /[MatMul_948]\n",
      "Ignore MatMul due to non constant B: /[MatMul_950]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1037]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1039]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1126]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1128]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1215]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1217]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1304]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1306]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1393]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1395]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1482]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1484]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1571]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1573]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1660]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1662]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1749]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1751]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1838]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1840]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1927]\n",
      "Ignore MatMul due to non constant B: /[MatMul_1929]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2016]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2018]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2105]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2107]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2194]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2196]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2283]\n",
      "Ignore MatMul due to non constant B: /[MatMul_2285]\n"
     ]
    }
   ],
   "source": [
    "quantize_dynamic(\"./outputs/jamo_base_model.onnx\",\n",
    "                 \"./outputs/quantized_jamo_base_model.onnx\",\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess_options = onnxruntime.SessionOptions()\n",
    "sess_options.graph_optimization_level = onnxruntime.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "session = onnxruntime.InferenceSession(\"./outputs/jamo_base_model.onnx\", sess_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66976,)\n",
      "-0.12826538 0.11135864\n"
     ]
    }
   ],
   "source": [
    "array,_ = librosa.load('./service_1/Assets/test_data_1.wav',16000)\n",
    "print(array.shape)\n",
    "print(array.min(), array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66976,)\n",
      "-7.489833 6.522962\n"
     ]
    }
   ],
   "source": [
    "array = processor(array, sampling_rate=16000).input_values[0]\n",
    "print(array.shape)\n",
    "print(array.min(), array.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 209, 111)\n",
      "[[109 107   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   4   4\n",
      "   13  13   0   8  12  12  20   0   0  50   0  20  20   4   4  13  13   0\n",
      "   42  13  13   0  33  33   0   0  67   0  13   0   0   4   4  85   0  35\n",
      "    0  13  13   0   0  85  85   0   8   8   0   0   0   0  33   0   8   8\n",
      "    0   0   0  17   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0  42   0   4   4  85  98  98   4]]\n"
     ]
    }
   ],
   "source": [
    "ortvalue = onnxruntime.OrtValue.ortvalue_from_numpy(array)\n",
    "results = session.run([\"output\"],{\"input\":array.reshape(1,-1)})\n",
    "# print(results)\n",
    "print(results[0].shape)\n",
    "print(np.argmax(results[0],axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ids = np.argmax(results[0],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ㅣ': 8, 'ㄶ': 9, 'V': 10, 'C': 11, 'ㅆ': 12, 'ㅇ': 13, 'k': 14, 't': 15, 'ㄼ': 16, 'ㅋ': 17, 'ㅚ': 18, 'ㄵ': 19, 'ㄴ': 20, 'ㅉ': 21, 'ㅜ': 22, 'b': 23, 'o': 24, 'B': 25, 'ㅛ': 26, 'v': 27, 'I': 28, 'i': 29, 'X': 30, 'ㄱ': 31, 'ㅄ': 32, 'ㅅ': 33, 'ㅠ': 34, 'ㅓ': 35, 'L': 36, 'm': 37, 'Z': 38, 'q': 39, 'ㄸ': 40, 'G': 41, 'ㅕ': 42, 'K': 43, 'd': 44, 'S': 45, 'Y': 46, 'M': 47, 'h': 48, 'w': 49, 'ㅡ': 50, 'ㅍ': 51, 'ㅐ': 52, 'j': 53, 'ㄷ': 54, 'ㄽ': 55, 'p': 56, 'ㄾ': 57, 'e': 58, 'N': 59, 'ㅞ': 60, 'x': 61, 'ㅒ': 62, 'ㅑ': 63, 'H': 64, 'r': 65, 'T': 66, 'ㅏ': 67, 'g': 68, 'ㄹ': 69, 'ㅀ': 70, 'ㄻ': 71, 'J': 72, 'u': 73, 'A': 74, 'ㄿ': 75, 'y': 76, 'F': 77, 'ㄲ': 78, 'c': 79, 'ㅔ': 80, 'ㅎ': 81, 'O': 82, 'ㅌ': 83, 'ㅢ': 84, 'ㅈ': 85, 'ㅁ': 86, 'ㅊ': 87, 'ㅙ': 88, 'E': 89, 'ㅖ': 90, 'P': 91, 'n': 92, 'Q': 93, 'l': 94, 'ㄳ': 95, 'ㅟ': 96, 'z': 97, 'ㅝ': 98, 'D': 99, 's': 100, 'ㅘ': 101, 'ㅃ': 102, 'R': 103, 'f': 104, 'a': 105, 'W': 106, 'ㅗ': 107, 'U': 108, 'ㅂ': 109, 'ㄺ': 110, '<pad>': 0, '<s>': 1, '</s>': 2, '<unk>': 3, '|': 4, '<b>': 5, '<n>': 6, '<l>': 7}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('vocab_jamos.json','r') as f:\n",
    "    word_to_index = json.load(f)\n",
    "print(word_to_index)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{8: 'ㅣ', 9: 'ㄶ', 10: 'V', 11: 'C', 12: 'ㅆ', 13: 'ㅇ', 14: 'k', 15: 't', 16: 'ㄼ', 17: 'ㅋ', 18: 'ㅚ', 19: 'ㄵ', 20: 'ㄴ', 21: 'ㅉ', 22: 'ㅜ', 23: 'b', 24: 'o', 25: 'B', 26: 'ㅛ', 27: 'v', 28: 'I', 29: 'i', 30: 'X', 31: 'ㄱ', 32: 'ㅄ', 33: 'ㅅ', 34: 'ㅠ', 35: 'ㅓ', 36: 'L', 37: 'm', 38: 'Z', 39: 'q', 40: 'ㄸ', 41: 'G', 42: 'ㅕ', 43: 'K', 44: 'd', 45: 'S', 46: 'Y', 47: 'M', 48: 'h', 49: 'w', 50: 'ㅡ', 51: 'ㅍ', 52: 'ㅐ', 53: 'j', 54: 'ㄷ', 55: 'ㄽ', 56: 'p', 57: 'ㄾ', 58: 'e', 59: 'N', 60: 'ㅞ', 61: 'x', 62: 'ㅒ', 63: 'ㅑ', 64: 'H', 65: 'r', 66: 'T', 67: 'ㅏ', 68: 'g', 69: 'ㄹ', 70: 'ㅀ', 71: 'ㄻ', 72: 'J', 73: 'u', 74: 'A', 75: 'ㄿ', 76: 'y', 77: 'F', 78: 'ㄲ', 79: 'c', 80: 'ㅔ', 81: 'ㅎ', 82: 'O', 83: 'ㅌ', 84: 'ㅢ', 85: 'ㅈ', 86: 'ㅁ', 87: 'ㅊ', 88: 'ㅙ', 89: 'E', 90: 'ㅖ', 91: 'P', 92: 'n', 93: 'Q', 94: 'l', 95: 'ㄳ', 96: 'ㅟ', 97: 'z', 98: 'ㅝ', 99: 'D', 100: 's', 101: 'ㅘ', 102: 'ㅃ', 103: 'R', 104: 'f', 105: 'a', 106: 'W', 107: 'ㅗ', 108: 'U', 109: 'ㅂ', 110: 'ㄺ', 0: '<pad>', 1: '<s>', 2: '</s>', 3: '<unk>', 4: '|', 5: '<b>', 6: '<n>', 7: '<l>'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word = {index:word for word,index in word_to_index.items()}\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅂ', 'ㅗ', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '|', '|', 'ㅇ', 'ㅇ', '<pad>', 'ㅣ', 'ㅆ', 'ㅆ', 'ㄴ', '<pad>', '<pad>', 'ㅡ', '<pad>', 'ㄴ', 'ㄴ', '|', '|', 'ㅇ', 'ㅇ', '<pad>', 'ㅕ', 'ㅇ', 'ㅇ', '<pad>', 'ㅅ', 'ㅅ', '<pad>', '<pad>', 'ㅏ', '<pad>', 'ㅇ', '<pad>', '<pad>', '|', '|', 'ㅈ', '<pad>', 'ㅓ', '<pad>', 'ㅇ', 'ㅇ', '<pad>', '<pad>', 'ㅈ', 'ㅈ', '<pad>', 'ㅣ', 'ㅣ', '<pad>', '<pad>', '<pad>', '<pad>', 'ㅅ', '<pad>', 'ㅣ', 'ㅣ', '<pad>', '<pad>', '<pad>', 'ㅋ', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', 'ㅕ', '<pad>', '|', '|', 'ㅈ', 'ㅝ', 'ㅝ', '|']\n"
     ]
    }
   ],
   "source": [
    "pred_str = [index_to_word[idx] for idx in pred_ids.flatten()]\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ㅂㅗ||ㅇㅇㅣㅆㅆㄴㅡㄴㄴ||ㅇㅇㅕㅇㅇㅅㅅㅏㅇ||ㅈㅓㅇㅇㅈㅈㅣㅣㅅㅣㅣㅋㅕ||ㅈㅝㅝ|\n"
     ]
    }
   ],
   "source": [
    "remove_pad_token = re.sub('<pad>','',''.join(pred_str))\n",
    "print(remove_pad_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ㅂ', 'ㅗ', ' ', 'ㅇ', 'ㅣ', 'ㅆ', 'ㄴ', 'ㅡ', 'ㄴ', ' ', 'ㅇ', 'ㅕ', 'ㅇ', 'ㅅ', 'ㅏ', 'ㅇ', ' ', 'ㅈ', 'ㅓ', 'ㅇ', 'ㅈ', 'ㅣ', 'ㅅ', 'ㅣ', 'ㅋ', 'ㅕ', ' ', 'ㅈ', 'ㅝ', ' ']\n"
     ]
    }
   ],
   "source": [
    "ctc = []\n",
    "tmp = \"\"\n",
    "for s in remove_pad_token:\n",
    "    if s == '|':\n",
    "        s = \" \"\n",
    "    if s == tmp:\n",
    "        continue\n",
    "    else:\n",
    "        ctc.append(s)\n",
    "    tmp = s\n",
    "print(ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ㅂㅗ ㅇㅣㅆㄴㅡㄴ ㅇㅕㅇㅅㅏㅇ ㅈㅓㅇㅈㅣㅅㅣㅋㅕ ㅈㅝ '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join(ctc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'보 있는 영상 정지시켜 줘'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from unicode import join_jamos\n",
    "join_jamos(\"\".join(ctc).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47040,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array,_ = librosa.load('./dataset/audio/script1_g_0044-6002-01-01-KSM-F-05-A.wav',16000)\n",
    "array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'다음 주까지 날씨가 어때'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = processor(array, sampling_rate=16000).input_values[0]\n",
    "results = session.run([\"output\"],{\"input\":array.reshape(1,-1)})\n",
    "pred_ids = np.argmax(results[0],axis=-1)\n",
    "pred_str = [index_to_word[idx] for idx in pred_ids.flatten()]\n",
    "remove_pad_token = re.sub('<pad>','',''.join(pred_str))\n",
    "ctc = []\n",
    "tmp = \"\"\n",
    "for s in remove_pad_token:\n",
    "    if s == '|':\n",
    "        s = \" \"\n",
    "    if s == tmp:\n",
    "        continue\n",
    "    else:\n",
    "        ctc.append(s)\n",
    "    tmp = s\n",
    "join_jamos(\"\".join(ctc).strip())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('STT')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19631f30805cf65d5465564d75f0fe7c05dee5c1f7be198222dbe754da644e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
