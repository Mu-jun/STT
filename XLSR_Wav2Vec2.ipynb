{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jrenWcqEmZBb"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install datasets==1.13.3\n",
        "!pip install transformers==4.11.3\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLCZvETJuFaO"
      },
      "source": [
        "## Create Wav2Vec2CTCTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using custom data configuration default-41fc3c5f4c361674\n",
            "Reusing dataset csv (C:\\Users\\Mu-jun\\.cache\\huggingface\\datasets\\csv\\default-41fc3c5f4c361674\\0.0.0\\bf68a4c4aefa545d0712b2fcbb1b327f905bbe2f6425fbc5e8c25234acb9e14a)\n"
          ]
        }
      ],
      "source": [
        "all_data = load_dataset('csv',data_files='./order_speech_ko.csv',split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['src', 'text'],\n",
              "    num_rows: 142367\n",
              "})"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17316</th>\n",
              "      <td>script1_g_0071-6661-01-01-YJK-M-04-A.wav</td>\n",
              "      <td>내일 오존 주의보 떴어?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            src           text\n",
              "17316  script1_g_0071-6661-01-01-YJK-M-04-A.wav  내일 오존 주의보 떴어?"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(all_data)\n",
        "df.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G34Hj6BgnK3L"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
        "\n",
        "def remove_special_characters(batch):\n",
        "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Parameter 'function'=<function remove_special_characters at 0x000001824DC06DC8> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "26282da2333e44ad82ffe9041ffb5af0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/142367 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "remove_spectial_char_data = all_data.map(remove_special_characters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>src</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>script1_g_0044-6001-01-01-KSM-F-05-A.wav</td>\n",
              "      <td>보고 있는 영상 정지시켜 줘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>script1_g_0044-6002-01-01-KSM-F-05-A.wav</td>\n",
              "      <td>다음 주까지 날씨가 어때</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>script1_g_0044-6003-01-01-KSM-F-05-A.wav</td>\n",
              "      <td>나 대신 점등해 줘</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>script1_g_0044-6004-01-01-KSM-F-05-A.wav</td>\n",
              "      <td>이번 주 대체로 흐린지 궁금해</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>script1_g_0044-6005-01-01-KSM-F-05-A.wav</td>\n",
              "      <td>지금 당장 취침 등 꺼 줘</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        src               text\n",
              "0  script1_g_0044-6001-01-01-KSM-F-05-A.wav   보고 있는 영상 정지시켜 줘 \n",
              "1  script1_g_0044-6002-01-01-KSM-F-05-A.wav     다음 주까지 날씨가 어때 \n",
              "2  script1_g_0044-6003-01-01-KSM-F-05-A.wav        나 대신 점등해 줘 \n",
              "3  script1_g_0044-6004-01-01-KSM-F-05-A.wav  이번 주 대체로 흐린지 궁금해 \n",
              "4  script1_g_0044-6005-01-01-KSM-F-05-A.wav    지금 당장 취침 등 꺼 줘 "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame(remove_spectial_char_data)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZsimiwGSnWDY"
      },
      "outputs": [],
      "source": [
        "def extract_all_chars(batch):\n",
        "  all_text = \" \".join(batch[\"text\"])\n",
        "  vocab = list(set(all_text))\n",
        "  return {\"vocab\": [vocab], \"all_text\": [all_text]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d5c8d46002141909106553adf42f76d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "char_vocab = remove_spectial_char_data.map(\n",
        "    extract_all_chars,\n",
        "    batched=True,\n",
        "    batch_size=-1,\n",
        "    keep_in_memory=True,\n",
        "    remove_columns=remove_spectial_char_data.column_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['all_text', 'vocab'],\n",
              "    num_rows: 1\n",
              "})"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "char_vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab_list = list(set(char_vocab[\"vocab\"][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'캄': 0,\n",
              " '랜': 1,\n",
              " '딱': 2,\n",
              " '언': 3,\n",
              " '욱': 4,\n",
              " '슬': 5,\n",
              " '릴': 6,\n",
              " \"'\": 7,\n",
              " '뭔': 8,\n",
              " '뽑': 9,\n",
              " '라': 10,\n",
              " '택': 11,\n",
              " '십': 12,\n",
              " '즌': 13,\n",
              " '내': 14,\n",
              " '줄': 15,\n",
              " '왜': 16,\n",
              " 'c': 17,\n",
              " '딸': 18,\n",
              " '밖': 19,\n",
              " '을': 20,\n",
              " '떼': 21,\n",
              " '곧': 22,\n",
              " '깜': 23,\n",
              " '컨': 24,\n",
              " '련': 25,\n",
              " 'v': 26,\n",
              " '졌': 27,\n",
              " '거': 28,\n",
              " '꿀': 29,\n",
              " '둔': 30,\n",
              " '햇': 31,\n",
              " '읽': 32,\n",
              " '랐': 33,\n",
              " '정': 34,\n",
              " '아': 35,\n",
              " '끌': 36,\n",
              " '쉬': 37,\n",
              " '톱': 38,\n",
              " '럼': 39,\n",
              " '권': 40,\n",
              " '년': 41,\n",
              " '혹': 42,\n",
              " '이': 43,\n",
              " '캐': 44,\n",
              " '익': 45,\n",
              " '산': 46,\n",
              " '영': 47,\n",
              " 'b': 48,\n",
              " '기': 49,\n",
              " '것': 50,\n",
              " '룸': 51,\n",
              " '품': 52,\n",
              " '흥': 53,\n",
              " '춤': 54,\n",
              " '트': 55,\n",
              " '매': 56,\n",
              " '맥': 57,\n",
              " '했': 58,\n",
              " '끄': 59,\n",
              " '루': 60,\n",
              " '켤': 61,\n",
              " '론': 62,\n",
              " '떨': 63,\n",
              " '랍': 64,\n",
              " '굽': 65,\n",
              " '디': 66,\n",
              " '흘': 67,\n",
              " '특': 68,\n",
              " '맙': 69,\n",
              " '축': 70,\n",
              " '키': 71,\n",
              " '쎄': 72,\n",
              " '류': 73,\n",
              " '균': 74,\n",
              " '둡': 75,\n",
              " '냄': 76,\n",
              " '미': 77,\n",
              " '포': 78,\n",
              " '화': 79,\n",
              " '엔': 80,\n",
              " '식': 81,\n",
              " '엘': 82,\n",
              " '야': 83,\n",
              " '말': 84,\n",
              " '친': 85,\n",
              " '짝': 86,\n",
              " '냐': 87,\n",
              " '괜': 88,\n",
              " '탕': 89,\n",
              " '색': 90,\n",
              " '입': 91,\n",
              " '게': 92,\n",
              " '띄': 93,\n",
              " '끝': 94,\n",
              " '관': 95,\n",
              " '별': 96,\n",
              " '꼭': 97,\n",
              " '풀': 98,\n",
              " '물': 99,\n",
              " '즉': 100,\n",
              " '른': 101,\n",
              " 't': 102,\n",
              " '치': 103,\n",
              " '눈': 104,\n",
              " '안': 105,\n",
              " '처': 106,\n",
              " '착': 107,\n",
              " '돼': 108,\n",
              " '딪': 109,\n",
              " '주': 110,\n",
              " '현': 111,\n",
              " '곤': 112,\n",
              " '센': 113,\n",
              " '좋': 114,\n",
              " '재': 115,\n",
              " '열': 116,\n",
              " '끼': 117,\n",
              " '블': 118,\n",
              " '닫': 119,\n",
              " '용': 120,\n",
              " '렸': 121,\n",
              " '조': 122,\n",
              " '출': 123,\n",
              " '파': 124,\n",
              " '책': 125,\n",
              " '요': 126,\n",
              " '뜨': 127,\n",
              " '새': 128,\n",
              " '답': 129,\n",
              " '하': 130,\n",
              " '몸': 131,\n",
              " '었': 132,\n",
              " '뱅': 133,\n",
              " '줘': 134,\n",
              " '운': 135,\n",
              " '즘': 136,\n",
              " '잠': 137,\n",
              " '핫': 138,\n",
              " '막': 139,\n",
              " '히': 140,\n",
              " '데': 141,\n",
              " '클': 142,\n",
              " '율': 143,\n",
              " '픽': 144,\n",
              " '학': 145,\n",
              " '또': 146,\n",
              " '전': 147,\n",
              " '뤄': 148,\n",
              " '탐': 149,\n",
              " '려': 150,\n",
              " '험': 151,\n",
              " '없': 152,\n",
              " '런': 153,\n",
              " '법': 154,\n",
              " '같': 155,\n",
              " '최': 156,\n",
              " '공': 157,\n",
              " '봐': 158,\n",
              " '핑': 159,\n",
              " '줬': 160,\n",
              " '과': 161,\n",
              " '층': 162,\n",
              " '낭': 163,\n",
              " '손': 164,\n",
              " '네': 165,\n",
              " '놀': 166,\n",
              " '성': 167,\n",
              " '싶': 168,\n",
              " '석': 169,\n",
              " '다': 170,\n",
              " '교': 171,\n",
              " '단': 172,\n",
              " '어': 173,\n",
              " '번': 174,\n",
              " '프': 175,\n",
              " '필': 176,\n",
              " '잘': 177,\n",
              " '일': 178,\n",
              " '역': 179,\n",
              " '혼': 180,\n",
              " '낫': 181,\n",
              " '낮': 182,\n",
              " '팝': 183,\n",
              " '봅': 184,\n",
              " '초': 185,\n",
              " '완': 186,\n",
              " '음': 187,\n",
              " '삼': 188,\n",
              " '꽈': 189,\n",
              " '브': 190,\n",
              " '건': 191,\n",
              " '못': 192,\n",
              " '락': 193,\n",
              " '꿔': 194,\n",
              " '놔': 195,\n",
              " '쳐': 196,\n",
              " '읊': 197,\n",
              " '팜': 198,\n",
              " '올': 199,\n",
              " '제': 200,\n",
              " '준': 201,\n",
              " '랑': 202,\n",
              " '빌': 203,\n",
              " '신': 204,\n",
              " '남': 205,\n",
              " '낌': 206,\n",
              " '꾸': 207,\n",
              " '대': 208,\n",
              " '명': 209,\n",
              " '여': 210,\n",
              " '타': 211,\n",
              " '틀': 212,\n",
              " '샷': 213,\n",
              " '텐': 214,\n",
              " '겟': 215,\n",
              " '까': 216,\n",
              " '무': 217,\n",
              " '쪼': 218,\n",
              " '렴': 219,\n",
              " '욜': 220,\n",
              " '실': 221,\n",
              " '륙': 222,\n",
              " '셔': 223,\n",
              " '슈': 224,\n",
              " '홈': 225,\n",
              " '에': 226,\n",
              " '엠': 227,\n",
              " '녹': 228,\n",
              " '때': 229,\n",
              " '팀': 230,\n",
              " '람': 231,\n",
              " '많': 232,\n",
              " '긴': 233,\n",
              " '낸': 234,\n",
              " '봤': 235,\n",
              " '밈': 236,\n",
              " '깨': 237,\n",
              " '겨': 238,\n",
              " '상': 239,\n",
              " '한': 240,\n",
              " '크': 241,\n",
              " '갔': 242,\n",
              " '룹': 243,\n",
              " '며': 244,\n",
              " '터': 245,\n",
              " '씨': 246,\n",
              " '쌀': 247,\n",
              " '만': 248,\n",
              " '망': 249,\n",
              " '능': 250,\n",
              " '딘': 251,\n",
              " '간': 252,\n",
              " '융': 253,\n",
              " '두': 254,\n",
              " '코': 255,\n",
              " '넘': 256,\n",
              " '께': 257,\n",
              " '2': 258,\n",
              " '검': 259,\n",
              " '은': 260,\n",
              " '앞': 261,\n",
              " '확': 262,\n",
              " '동': 263,\n",
              " '길': 264,\n",
              " '녁': 265,\n",
              " '월': 266,\n",
              " '체': 267,\n",
              " '돌': 268,\n",
              " '느': 269,\n",
              " '생': 270,\n",
              " '따': 271,\n",
              " '왔': 272,\n",
              " '뉴': 273,\n",
              " '지': 274,\n",
              " '합': 275,\n",
              " '빙': 276,\n",
              " '스': 277,\n",
              " '혔': 278,\n",
              " '변': 279,\n",
              " '개': 280,\n",
              " '높': 281,\n",
              " '불': 282,\n",
              " '예': 283,\n",
              " '홍': 284,\n",
              " '로': 285,\n",
              " '힐': 286,\n",
              " '떴': 287,\n",
              " '찮': 288,\n",
              " '꺼': 289,\n",
              " '던': 290,\n",
              " '금': 291,\n",
              " '챙': 292,\n",
              " '엇': 293,\n",
              " '울': 294,\n",
              " '머': 295,\n",
              " '맛': 296,\n",
              " '웠': 297,\n",
              " '쇼': 298,\n",
              " '보': 299,\n",
              " '살': 300,\n",
              " '누': 301,\n",
              " '렇': 302,\n",
              " '옵': 303,\n",
              " '항': 304,\n",
              " '배': 305,\n",
              " '외': 306,\n",
              " '표': 307,\n",
              " '마': 308,\n",
              " '급': 309,\n",
              " '원': 310,\n",
              " '깐': 311,\n",
              " '린': 312,\n",
              " '티': 313,\n",
              " '겠': 314,\n",
              " '횐': 315,\n",
              " '놓': 316,\n",
              " '앰': 317,\n",
              " '드': 318,\n",
              " '행': 319,\n",
              " '복': 320,\n",
              " '약': 321,\n",
              " '래': 322,\n",
              " '우': 323,\n",
              " '늘': 324,\n",
              " '헤': 325,\n",
              " '끗': 326,\n",
              " '강': 327,\n",
              " '바': 328,\n",
              " '혀': 329,\n",
              " '둠': 330,\n",
              " '날': 331,\n",
              " '효': 332,\n",
              " '애': 333,\n",
              " '뷱': 334,\n",
              " '쳤': 335,\n",
              " '떤': 336,\n",
              " '즐': 337,\n",
              " '춰': 338,\n",
              " '퍼': 339,\n",
              " '였': 340,\n",
              " '탑': 341,\n",
              " '름': 342,\n",
              " '찌': 343,\n",
              " '임': 344,\n",
              " '츠': 345,\n",
              " '뭇': 346,\n",
              " '텔': 347,\n",
              " '삭': 348,\n",
              " '덤': 349,\n",
              " '괄': 350,\n",
              " '뭘': 351,\n",
              " '차': 352,\n",
              " '걷': 353,\n",
              " '쉼': 354,\n",
              " '볼': 355,\n",
              " '커': 356,\n",
              " '달': 357,\n",
              " '킬': 358,\n",
              " '카': 359,\n",
              " '힌': 360,\n",
              " '후': 361,\n",
              " '감': 362,\n",
              " '계': 363,\n",
              " '림': 364,\n",
              " '업': 365,\n",
              " '맑': 366,\n",
              " '알': 367,\n",
              " '테': 368,\n",
              " '놨': 369,\n",
              " '되': 370,\n",
              " '장': 371,\n",
              " '저': 372,\n",
              " '나': 373,\n",
              " '적': 374,\n",
              " '규': 375,\n",
              " '절': 376,\n",
              " '도': 377,\n",
              " '씻': 378,\n",
              " '률': 379,\n",
              " '곡': 380,\n",
              " '았': 381,\n",
              " '홉': 382,\n",
              " '벽': 383,\n",
              " '면': 384,\n",
              " '악': 385,\n",
              " '모': 386,\n",
              " '쓸': 387,\n",
              " '록': 388,\n",
              " '비': 389,\n",
              " '측': 390,\n",
              " '오': 391,\n",
              " '청': 392,\n",
              " '국': 393,\n",
              " '튼': 394,\n",
              " '슨': 395,\n",
              " '멍': 396,\n",
              " '갈': 397,\n",
              " '든': 398,\n",
              " '직': 399,\n",
              " '쪽': 400,\n",
              " '않': 401,\n",
              " '채': 402,\n",
              " '력': 403,\n",
              " '설': 404,\n",
              " '를': 405,\n",
              " '와': 406,\n",
              " '쯤': 407,\n",
              " '회': 408,\n",
              " '할': 409,\n",
              " '태': 410,\n",
              " '얼': 411,\n",
              " '분': 412,\n",
              " '롤': 413,\n",
              " '집': 414,\n",
              " '짧': 415,\n",
              " '목': 416,\n",
              " '위': 417,\n",
              " '민': 418,\n",
              " '듣': 419,\n",
              " '빛': 420,\n",
              " '결': 421,\n",
              " '침': 422,\n",
              " '본': 423,\n",
              " '폭': 424,\n",
              " '걸': 425,\n",
              " '짜': 426,\n",
              " '량': 427,\n",
              " '호': 428,\n",
              " '곳': 429,\n",
              " '문': 430,\n",
              " '리': 431,\n",
              " '났': 432,\n",
              " '쫏': 433,\n",
              " '들': 434,\n",
              " '둘': 435,\n",
              " '증': 436,\n",
              " '늦': 437,\n",
              " '진': 438,\n",
              " '받': 439,\n",
              " '뀌': 440,\n",
              " '셋': 441,\n",
              " '해': 442,\n",
              " '독': 443,\n",
              " '됐': 444,\n",
              " '워': 445,\n",
              " '씬': 446,\n",
              " '취': 447,\n",
              " '뒤': 448,\n",
              " '쩐': 449,\n",
              " '넣': 450,\n",
              " '쓰': 451,\n",
              " '있': 452,\n",
              " '먼': 453,\n",
              " '둬': 454,\n",
              " '자': 455,\n",
              " '존': 456,\n",
              " '염': 457,\n",
              " '시': 458,\n",
              " '광': 459,\n",
              " '르': 460,\n",
              " '립': 461,\n",
              " '논': 462,\n",
              " '형': 463,\n",
              " '통': 464,\n",
              " '메': 465,\n",
              " '맞': 466,\n",
              " '찐': 467,\n",
              " '곱': 468,\n",
              " '흐': 469,\n",
              " '꼈': 470,\n",
              " '밝': 471,\n",
              " '략': 472,\n",
              " '너': 473,\n",
              " '쫌': 474,\n",
              " '편': 475,\n",
              " '펼': 476,\n",
              " '큼': 477,\n",
              " '액': 478,\n",
              " '러': 479,\n",
              " '세': 480,\n",
              " '낼': 481,\n",
              " '작': 482,\n",
              " '부': 483,\n",
              " '수': 484,\n",
              " '창': 485,\n",
              " '싫': 486,\n",
              " '픈': 487,\n",
              " '연': 488,\n",
              " '사': 489,\n",
              " '먹': 490,\n",
              " '케': 491,\n",
              " '좀': 492,\n",
              " '잡': 493,\n",
              " '중': 494,\n",
              " '뭐': 495,\n",
              " '빨': 496,\n",
              " '송': 497,\n",
              " '으': 498,\n",
              " '3': 499,\n",
              " '추': 500,\n",
              " '찾': 501,\n",
              " ' ': 502,\n",
              " '팔': 503,\n",
              " '반': 504,\n",
              " '5': 505,\n",
              " '져': 506,\n",
              " '베': 507,\n",
              " '구': 508,\n",
              " '심': 509,\n",
              " '끓': 510,\n",
              " '잔': 511,\n",
              " '큰': 512,\n",
              " '궁': 513,\n",
              " '퇴': 514,\n",
              " '틴': 515,\n",
              " '피': 516,\n",
              " '콘': 517,\n",
              " '풍': 518,\n",
              " '각': 519,\n",
              " '속': 520,\n",
              " '농': 521,\n",
              " '종': 522,\n",
              " '근': 523,\n",
              " '란': 524,\n",
              " '펴': 525,\n",
              " '넷': 526,\n",
              " '유': 527,\n",
              " '닭': 528,\n",
              " '플': 529,\n",
              " '소': 530,\n",
              " '온': 531,\n",
              " '칼': 532,\n",
              " '멈': 533,\n",
              " '몰': 534,\n",
              " '몇': 535,\n",
              " '는': 536,\n",
              " '귀': 537,\n",
              " '순': 538,\n",
              " '첸': 539,\n",
              " '서': 540,\n",
              " '인': 541,\n",
              " '뀐': 542,\n",
              " '등': 543,\n",
              " 'm': 544,\n",
              " '팅': 545,\n",
              " '발': 546,\n",
              " '총': 547,\n",
              " '노': 548,\n",
              " '황': 549,\n",
              " '졸': 550,\n",
              " '덜': 551,\n",
              " '료': 552,\n",
              " '레': 553,\n",
              " '즈': 554,\n",
              " '떻': 555,\n",
              " '엌': 556,\n",
              " '점': 557,\n",
              " '더': 558,\n",
              " '얀': 559,\n",
              " '빠': 560,\n",
              " '환': 561,\n",
              " '토': 562,\n",
              " '얘': 563,\n",
              " '떠': 564,\n",
              " '껴': 565,\n",
              " '닥': 566,\n",
              " '핵': 567,\n",
              " '깥': 568,\n",
              " '의': 569,\n",
              " '뜰': 570,\n",
              " '가': 571,\n",
              " '난': 572,\n",
              " '니': 573,\n",
              " '뜻': 574,\n",
              " '당': 575,\n",
              " '투': 576,\n",
              " '될': 577,\n",
              " '선': 578,\n",
              " '고': 579,\n",
              " '땐': 580,\n",
              " '천': 581,\n",
              " '된': 582,\n",
              " '평': 583,\n",
              " '승': 584,\n",
              " '밤': 585,\n",
              " '탁': 586,\n",
              " '널': 587,\n",
              " '활': 588,\n",
              " '경': 589,\n",
              " '방': 590,\n",
              " '켜': 591,\n",
              " '북': 592,\n",
              " '빵': 593,\n",
              " '턴': 594,\n",
              " '그': 595,\n",
              " '습': 596,\n",
              " '칠': 597,\n",
              " '닝': 598,\n",
              " '휴': 599}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_dict = {v: k for k, v in enumerate(vocab_list)}\n",
        "vocab_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "_hi_HbR_rCKb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "602"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
        "del vocab_dict[\" \"]\n",
        "vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
        "vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
        "len(vocab_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rMWugphlrsZ1"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "with open('vocab.json', 'w') as vocab_file:\n",
        "    json.dump(vocab_dict, vocab_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YJUUl9lnryU-"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2CTCTokenizer\n",
        "\n",
        "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab.json\",\n",
        "                                 unk_token=\"[UNK]\",\n",
        "                                 pad_token=\"[PAD]\",\n",
        "                                 word_delimiter_token=\"|\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCtrdRsuuDix"
      },
      "source": [
        "## Create XLSR-Wav2Vec2 Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "O0vdrkhKr8D1"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2FeatureExtractor\n",
        "\n",
        "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1,\n",
        "                                             sampling_rate=16000,\n",
        "                                             padding_value=0.0,\n",
        "                                             do_normalize=True,\n",
        "                                             return_attention_mask=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "fY_Qm1dpsE78"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2Processor\n",
        "\n",
        "processor = Wav2Vec2Processor(feature_extractor=feature_extractor,\n",
        "                              tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KTUahP1PsL3g"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9tMSA3xKsVma"
      },
      "outputs": [],
      "source": [
        "# processor.save_pretrained(\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-ready\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZiv4zqyt2cY"
      },
      "source": [
        "## Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AscOxzgUsb50"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(batch):\n",
        "    audio = batch[\"audio\"]\n",
        "\n",
        "    # batched output is \"un-batched\"\n",
        "    batch[\"input_values\"] = processor(audio[\"array\"], sampling_rate=audio[\"sampling_rate\"]).input_values[0]\n",
        "    \n",
        "    with processor.as_target_processor():\n",
        "        batch[\"labels\"] = processor(batch[\"sentence\"]).input_ids\n",
        "    return batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StCtCQxDtuY3"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUTqiRY-tpXZ"
      },
      "source": [
        "## Set-up Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "nTlewiOzsyqR"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'torch'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2868\\2949795305.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataclasses\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdataclass\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfield\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Any, Dict, List, Optional, Union\n",
        "\n",
        "@dataclass\n",
        "class DataCollatorCTCWithPadding:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs received.\n",
        "    Args:\n",
        "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
        "            The processor used for proccessing the data.\n",
        "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
        "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
        "            among:\n",
        "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
        "              sequence if provided).\n",
        "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
        "              maximum acceptable input length for the model if that argument is not provided.\n",
        "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
        "              different lengths).\n",
        "        max_length (:obj:`int`, `optional`):\n",
        "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
        "        max_length_labels (:obj:`int`, `optional`):\n",
        "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
        "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
        "            If set will pad the sequence to a multiple of the provided value.\n",
        "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
        "            7.5 (Volta).\n",
        "    \"\"\"\n",
        "\n",
        "    processor: Wav2Vec2Processor\n",
        "    padding: Union[bool, str] = True\n",
        "    max_length: Optional[int] = None\n",
        "    max_length_labels: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "    pad_to_multiple_of_labels: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features: List[Dict[str, Union[List[int], torch.Tensor]]]) -> Dict[str, torch.Tensor]:\n",
        "        # split inputs and labels since they have to be of different lenghts and need\n",
        "        # different padding methods\n",
        "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
        "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
        "\n",
        "        batch = self.processor.pad(\n",
        "            input_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "        with self.processor.as_target_processor():\n",
        "            labels_batch = self.processor.pad(\n",
        "                label_features,\n",
        "                padding=self.padding,\n",
        "                max_length=self.max_length_labels,\n",
        "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
        "                return_tensors=\"pt\",\n",
        "            )\n",
        "\n",
        "        # replace padding with -100 to ignore loss correctly\n",
        "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
        "\n",
        "        batch[\"labels\"] = labels\n",
        "\n",
        "        return batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WmfIPs18tGQb"
      },
      "outputs": [],
      "source": [
        "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vJjfNy9-tJM6"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset, load_metric, Audio\n",
        "\n",
        "wer_metric = load_metric(\"wer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03mNNUfNthSZ"
      },
      "outputs": [],
      "source": [
        "def compute_metrics(pred):\n",
        "    pred_logits = pred.predictions\n",
        "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
        "\n",
        "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
        "\n",
        "    pred_str = processor.batch_decode(pred_ids)\n",
        "    # we do not want to group tokens when computing the metrics\n",
        "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
        "\n",
        "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
        "\n",
        "    return {\"wer\": wer}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vgRoeQHvTqk"
      },
      "source": [
        "## Import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iyv4qaclue6n"
      },
      "outputs": [],
      "source": [
        "from transformers import Wav2Vec2ForCTC\n",
        "\n",
        "model = Wav2Vec2ForCTC.from_pretrained(\n",
        "    \"facebook/wav2vec2-large-xlsr-53\", \n",
        "    attention_dropout=0.1,\n",
        "    hidden_dropout=0.1,\n",
        "    feat_proj_dropout=0.0,\n",
        "    mask_time_prob=0.05,\n",
        "    layerdrop=0.1,\n",
        "    ctc_loss_reduction=\"mean\", \n",
        "    pad_token_id=processor.tokenizer.pad_token_id,\n",
        "    vocab_size=len(processor.tokenizer)\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MaYmsSutuv26"
      },
      "source": [
        "XLSR-Wav2Vec2의 첫 번째 구성 요소는 원시 음성 신호에서 음향적으로 의미가 있지만 문맥적으로 독립적인 기능을 추출하는 데 사용되는 CNN 계층 스택으로 구성됩니다.  \n",
        "모델의 이 부분은 사전 교육 중에 이미 충분히 훈련되었으며 논문에 명시된 바와 같이 더 이상 미세 조정할 필요가 없습니다. 따라서 특징 추출 부분의 모든 파라미터에 대해 require_grad를 False로 설정할 수 있다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VX8z6PpuhqG"
      },
      "outputs": [],
      "source": [
        "model.freeze_feature_extractor()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAfoHUk9vGxd"
      },
      "source": [
        "메모리를 절약하기 위해 그라데이션 체크포인팅을 활성화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZm6in_2vAIN"
      },
      "outputs": [],
      "source": [
        "model.gradient_checkpointing_enable()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h-aJNQplvQgn"
      },
      "source": [
        "## TrainingArguments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LuuwoeMvOnV"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-turkish-demo\",\n",
        "  output_dir=\"./wav2vec2-large-xlsr-turkish-demo\",\n",
        "  group_by_length=True,\n",
        "  per_device_train_batch_size=16,\n",
        "  gradient_accumulation_steps=2,\n",
        "  evaluation_strategy=\"steps\",\n",
        "  num_train_epochs=30,\n",
        "  fp16=True,\n",
        "  save_steps=100,\n",
        "  eval_steps=100,\n",
        "  logging_steps=10,\n",
        "  learning_rate=3e-4,\n",
        "  warmup_steps=500,\n",
        "  save_total_limit=2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VPmHz40vkeM"
      },
      "source": [
        "## Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6vhFC0BdvcOu"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    data_collator=data_collator,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=common_voice_train, # train_ds\n",
        "    eval_dataset=common_voice_test, # test_ds\n",
        "    tokenizer=processor.feature_extractor,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHGNj1NSvsFk"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-rJ8fokvjJb"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxpIR_X8w3Pq"
      },
      "source": [
        "CTC 손실을 사용하여 더 큰 데이터 세트에서 더 큰 모델을 미세 조정하려면 [여기서](https://github.com/huggingface/transformers/tree/master/examples/pytorch/speech-recognition#connectionist-temporal-classification-without-language-model-ctc-wo-lm) 공식 음성 인식 예를 살펴봐야 한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shZn6QzW0T1h"
      },
      "source": [
        "## Model predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umACSYoA0SV7"
      },
      "outputs": [],
      "source": [
        "model(audio_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "00.XLSR - Wav2Vec2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.7.13 ('STT')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "19631f30805cf65d5465564d75f0fe7c05dee5c1f7be198222dbe754da644e52"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
