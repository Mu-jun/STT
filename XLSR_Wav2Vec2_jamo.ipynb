{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./dataset/csv/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-2cf0bbc2a35b5d09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-2cf0bbc2a35b5d09\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7f86efb61664ab48b41a538cb3011e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d274ec4ac11d42a6b490b3e1957a46a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-2cf0bbc2a35b5d09\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "all_data = load_dataset(\n",
    "    'csv',\n",
    "    data_files=os.path.join(\n",
    "        data_path,\n",
    "        'order_speech_ko_ppt.csv' ## 4까지 완료\n",
    "    ),\n",
    "    sep='\\t',\n",
    "    split='train'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G34Hj6BgnK3L"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from unicode import split_syllables, join_jamos\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n",
    "    batch[\"text\"] = split_syllables(batch[\"text\"])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55f74a4bc52549d0958549503de161ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "remove_spectial_char_data = all_data.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLCZvETJuFaO"
   },
   "source": [
    "## Create Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YJUUl9lnryU-"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab_jamos.json\",\n",
    "                                 unk_token=\"<unk>\",\n",
    "                                 pad_token=\"<pad>\",\n",
    "                                 word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCtrdRsuuDix"
   },
   "source": [
    "## Create XLSR-Wav2Vec2 Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O0vdrkhKr8D1"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1,\n",
    "                                             sampling_rate=16000,\n",
    "                                             padding_value=0.0,\n",
    "                                             do_normalize=True,\n",
    "                                             return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fY_Qm1dpsE78"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor,\n",
    "                              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KTUahP1PsL3g"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9tMSA3xKsVma"
   },
   "outputs": [],
   "source": [
    "# processor.save_pretrained(\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add audio array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(batch):\n",
    "#     batch['array'],_ = librosa.load('./dataset/audio/'+batch['filename'],sr=16000)\n",
    "    batch['array'] = np.array(batch['array'][1:-1].split(',')).astype(np.float32)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347a171c36b24595816bb9590e89c64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "audio_data = remove_spectial_char_data.map(load_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio_data[0]['array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.2546227620181816e-13,\n",
       " -2.629366776391029e-12,\n",
       " 1.9561086691405327e-12,\n",
       " -1.0283167546643046e-11,\n",
       " 8.514041034690667e-12,\n",
       " -2.4210945748226465e-11,\n",
       " 2.9738985579674804e-11,\n",
       " -4.436709680200046e-11,\n",
       " 6.649177042294951e-11,\n",
       " -9.122887861812146e-11,\n",
       " 1.238807112446949e-10,\n",
       " -1.6133586133726396e-10,\n",
       " 1.923707027007282e-10,\n",
       " -1.9670189088660806e-10,\n",
       " 1.669526045189329e-10,\n",
       " -4.015029628212652e-11,\n",
       " -2.1462671917493736e-10,\n",
       " 7.055963591184877e-10,\n",
       " -1.4651054813796804e-09,\n",
       " 2.6427542376694646e-09,\n",
       " -4.313555290735849e-09,\n",
       " 6.549528919208569e-09,\n",
       " -9.393783528821587e-09,\n",
       " 1.2832559015407696e-08,\n",
       " -1.676772320990949e-08,\n",
       " 2.0905421393990764e-08,\n",
       " -2.491933592807527e-08,\n",
       " 2.8175202615443595e-08,\n",
       " -2.9930145473144876e-08,\n",
       " 2.9153149228022812e-08,\n",
       " -2.4710741897138178e-08,\n",
       " 1.527223325581417e-08,\n",
       " 5.53800338920496e-10,\n",
       " -2.412231125958897e-08,\n",
       " 5.6613931320725897e-08,\n",
       " -9.889456009659625e-08,\n",
       " 1.5128267705222243e-07,\n",
       " -2.1328249033558677e-07,\n",
       " 2.8364337367747794e-07,\n",
       " -3.5966033351542137e-07,\n",
       " 4.376163644792541e-07,\n",
       " -5.12028179855406e-07,\n",
       " 5.761860393249663e-07,\n",
       " -6.216547490112134e-07,\n",
       " 6.389303166542959e-07,\n",
       " -6.172625148792577e-07,\n",
       " 5.454249389913457e-07,\n",
       " -4.120502978821605e-07,\n",
       " 2.0636792896766565e-07,\n",
       " 8.095022963061638e-08,\n",
       " -4.5703606588176626e-07,\n",
       " 9.256947350877454e-07,\n",
       " -1.4867821391817415e-06,\n",
       " 2.1349160306272097e-06,\n",
       " -2.8591466616489924e-06,\n",
       " 3.6420060496311635e-06,\n",
       " -4.459535830392269e-06,\n",
       " 5.2811305977229495e-06,\n",
       " -6.0702304836013354e-06,\n",
       " 6.78556170896627e-06,\n",
       " -7.383341198874405e-06,\n",
       " 7.82314054958988e-06,\n",
       " -8.098333637462929e-06,\n",
       " 8.853395229380112e-06,\n",
       " 3.9505182940047234e-05,\n",
       " 0.00011508619354572147,\n",
       " 0.00018160643230658025,\n",
       " 0.00027551653329283,\n",
       " 0.000371545524103567,\n",
       " 0.00030289648566395044,\n",
       " 0.00012294035695958883,\n",
       " -0.0001257211552001536,\n",
       " 1.9364933905308135e-05,\n",
       " -0.00011306069063721225,\n",
       " 7.977828499861062e-05,\n",
       " 6.701872916892171e-05,\n",
       " -0.00015949616499710828,\n",
       " -0.00027120712911710143,\n",
       " -0.00026718518347479403,\n",
       " -0.00019364265608601272,\n",
       " -0.0006537100998684764,\n",
       " -0.0006920280866324902,\n",
       " -0.000555443752091378,\n",
       " -2.737940667429939e-05,\n",
       " 0.0002847545256372541,\n",
       " -0.0002853460318874568,\n",
       " 1.074861029337626e-05,\n",
       " 0.0006940505118109286,\n",
       " 0.000887773057911545,\n",
       " 0.0009458828717470169,\n",
       " 0.00025931757409125566,\n",
       " 0.0004980600206181407,\n",
       " 0.0004233420768287033,\n",
       " 0.000369772722478956,\n",
       " -0.00020717298320960253,\n",
       " -0.00016279745614156127,\n",
       " 0.00023940132814459503,\n",
       " -1.3460741683957167e-05,\n",
       " 0.0004066511755809188,\n",
       " -0.0004651763301808387,\n",
       " -0.0013979834038764238,\n",
       " -0.002097152639180422,\n",
       " -0.0018594173016026616,\n",
       " -0.001821055542677641,\n",
       " -0.001527324435301125,\n",
       " -0.0016124080866575241,\n",
       " -0.0014305555960163474,\n",
       " -0.0013631894253194332,\n",
       " -0.0007748898351565003,\n",
       " -0.0002731535932980478,\n",
       " 0.00013223050336819142,\n",
       " 0.0004885065136477351,\n",
       " 0.0001830197434173897,\n",
       " 0.0008212156244553626,\n",
       " 0.0009176105377264321,\n",
       " 0.0017105102306231856,\n",
       " 0.001095134299248457,\n",
       " 0.0009021610603667796,\n",
       " 0.0009458966669626534,\n",
       " 0.0003788397880271077,\n",
       " 0.00021046567417215556,\n",
       " -9.114811109611765e-05,\n",
       " -0.000920422316994518,\n",
       " -0.000654781935736537,\n",
       " -0.0006650554714724422,\n",
       " -0.0012442447477951646,\n",
       " -0.0012404684675857425,\n",
       " -0.002010310534387827,\n",
       " -0.002403578022494912,\n",
       " -0.002270875032991171,\n",
       " -0.0017695907736197114,\n",
       " -0.0016426531365141273,\n",
       " -0.0020262906327843666,\n",
       " -0.0024355538189411163,\n",
       " -0.002204202115535736,\n",
       " -0.002070272108539939,\n",
       " -0.0017227755161002278,\n",
       " -0.002312369178980589,\n",
       " -0.002473609521985054,\n",
       " -0.0027163380291312933,\n",
       " -0.0027793117333203554,\n",
       " -0.0029847044497728348,\n",
       " -0.003700419096276164,\n",
       " -0.003982860129326582,\n",
       " -0.004402103368192911,\n",
       " -0.004295867867767811,\n",
       " -0.004890650976449251,\n",
       " -0.005029668100178242,\n",
       " -0.005294259171932936,\n",
       " -0.005108686629682779,\n",
       " -0.005783336702734232,\n",
       " -0.005213525611907244,\n",
       " -0.004939272068440914,\n",
       " -0.005134697072207928,\n",
       " -0.004674928262829781,\n",
       " -0.005620742682367563,\n",
       " -0.005173176992684603,\n",
       " -0.0050531900487840176,\n",
       " -0.004813067149370909,\n",
       " -0.004414297640323639,\n",
       " -0.0037859459407627583,\n",
       " -0.003883478930220008,\n",
       " -0.0036354113835841417,\n",
       " -0.003285934217274189,\n",
       " -0.0036906965542584658,\n",
       " -0.0035901416558772326,\n",
       " -0.0038318773731589317,\n",
       " -0.0033186604268848896,\n",
       " -0.0032518701627850533,\n",
       " -0.0032427555415779352,\n",
       " -0.002846317831426859,\n",
       " -0.003500445745885372,\n",
       " -0.003297956893220544,\n",
       " -0.003265748731791973,\n",
       " -0.004357105121016502,\n",
       " -0.004208203870803118,\n",
       " -0.005345852579921484,\n",
       " -0.00620544096454978,\n",
       " -0.005976024549454451,\n",
       " -0.007115640211850405,\n",
       " -0.00771035673096776,\n",
       " -0.007786451373249292,\n",
       " -0.008561198599636555,\n",
       " -0.008853423409163952,\n",
       " -0.00829093437641859,\n",
       " -0.00878861267119646,\n",
       " -0.008846201002597809,\n",
       " -0.009075723588466644,\n",
       " -0.008800645358860493,\n",
       " -0.00821312703192234,\n",
       " -0.008063079789280891,\n",
       " -0.007445345167070627,\n",
       " -0.0073410626500844955,\n",
       " -0.007864673621952534,\n",
       " -0.007852144539356232,\n",
       " -0.007182154804468155,\n",
       " -0.006994402036070824,\n",
       " -0.005733498837798834,\n",
       " -0.005863886326551437,\n",
       " -0.006165843456983566,\n",
       " -0.0052424329333007336,\n",
       " -0.004059942904859781,\n",
       " -0.004422447178512812,\n",
       " -0.004346893168985844,\n",
       " -0.0038252330850809813,\n",
       " -0.004088045097887516,\n",
       " -0.00359579105861485,\n",
       " -0.0038716404233127832,\n",
       " -0.003806236432865262,\n",
       " -0.0041274745017290115,\n",
       " -0.004699940327554941,\n",
       " -0.0043947771191596985,\n",
       " -0.004284183960407972,\n",
       " -0.00467990105971694,\n",
       " -0.004633382428437471,\n",
       " -0.005293918773531914,\n",
       " -0.004749492276459932,\n",
       " -0.004210474900901318,\n",
       " -0.004313421901315451,\n",
       " -0.005044141318649054,\n",
       " -0.005379724781960249,\n",
       " -0.005413858685642481,\n",
       " -0.005385595373809338,\n",
       " -0.0049960254691541195,\n",
       " -0.005205200053751469,\n",
       " -0.004968992900103331,\n",
       " -0.005069747567176819,\n",
       " -0.0038850982673466206,\n",
       " -0.0039763422682881355,\n",
       " -0.003927283454686403,\n",
       " -0.0031666781287640333,\n",
       " -0.002940413309261203,\n",
       " -0.002690218621864915,\n",
       " -0.0032179022673517466,\n",
       " -0.002231449354439974,\n",
       " -0.002172349952161312,\n",
       " -0.0025304078590124846,\n",
       " -0.0024138966109603643,\n",
       " -0.0031841862946748734,\n",
       " -0.0032621468417346478,\n",
       " -0.003797910874709487,\n",
       " -0.003843022743239999,\n",
       " -0.004344758577644825,\n",
       " -0.004410439170897007,\n",
       " -0.0036803570110350847,\n",
       " -0.003792104311287403,\n",
       " -0.004092298448085785,\n",
       " -0.003903244622051716,\n",
       " -0.00429884297773242,\n",
       " -0.004107801243662834,\n",
       " -0.0032667412888258696,\n",
       " -0.003639980684965849,\n",
       " -0.0033430217299610376,\n",
       " -0.0033330360893160105,\n",
       " -0.0030740764923393726,\n",
       " -0.003094056388363242,\n",
       " -0.0028905842918902636,\n",
       " -0.0032852301374077797,\n",
       " -0.004028609022498131,\n",
       " -0.00325593538582325,\n",
       " -0.0028754265513271093,\n",
       " -0.0031692220363765955,\n",
       " -0.0037264886777848005,\n",
       " -0.004597461316734552,\n",
       " -0.004241895396262407,\n",
       " -0.004332086071372032,\n",
       " -0.0054700192995369434,\n",
       " -0.005702272988855839,\n",
       " -0.005811127834022045,\n",
       " -0.0051795365288853645,\n",
       " -0.004653074778616428,\n",
       " -0.00414067879319191,\n",
       " -0.00396526325494051,\n",
       " -0.004144821781665087,\n",
       " -0.0029741686303168535,\n",
       " -0.002993427449837327,\n",
       " -0.002788309473544359,\n",
       " -0.0022142715752124786,\n",
       " -0.002205122262239456,\n",
       " -0.0022574770264327526,\n",
       " -0.00223707128316164,\n",
       " -0.002431086264550686,\n",
       " -0.003392465878278017,\n",
       " -0.003242654725909233,\n",
       " -0.003452942008152604,\n",
       " -0.003249173751100898,\n",
       " -0.0037440157029777765,\n",
       " -0.0034067186061292887,\n",
       " -0.003891299245879054,\n",
       " -0.004196770489215851,\n",
       " -0.004533716011792421,\n",
       " -0.0053850822150707245,\n",
       " -0.005489297676831484,\n",
       " -0.006668115500360727,\n",
       " -0.0062361061573028564,\n",
       " -0.006526610814034939,\n",
       " -0.006525137927383184,\n",
       " -0.006155835464596748,\n",
       " -0.006472280714660883,\n",
       " -0.006764470133930445,\n",
       " -0.0061094327829778194,\n",
       " -0.006355552468448877,\n",
       " -0.006511911284178495,\n",
       " -0.00600207457318902,\n",
       " -0.006655190140008926,\n",
       " -0.006767313461750746,\n",
       " -0.006575949490070343,\n",
       " -0.006830782163888216,\n",
       " -0.006429590284824371,\n",
       " -0.006374049931764603,\n",
       " -0.006490090861916542,\n",
       " -0.005800653249025345,\n",
       " -0.005676725879311562,\n",
       " -0.005221489816904068,\n",
       " -0.004744669422507286,\n",
       " -0.005377072840929031,\n",
       " -0.0054444135166704655,\n",
       " -0.005154509097337723,\n",
       " -0.005637376103550196,\n",
       " -0.005513693671673536,\n",
       " -0.005480802617967129,\n",
       " -0.005484581459313631,\n",
       " -0.00579707371070981,\n",
       " -0.006378894671797752,\n",
       " -0.006545398849993944,\n",
       " -0.006936453748494387,\n",
       " -0.0066949487663805485,\n",
       " -0.006428102031350136,\n",
       " -0.006252703722566366,\n",
       " -0.005366687662899494,\n",
       " -0.005097547080367804,\n",
       " -0.0052034975960850716,\n",
       " -0.005027359817177057,\n",
       " -0.004483435302972794,\n",
       " -0.0041324663907289505,\n",
       " -0.0035756961442530155,\n",
       " -0.003863085526973009,\n",
       " -0.0037648652214556932,\n",
       " -0.003917772322893143,\n",
       " -0.0033272635191679,\n",
       " -0.002427436877042055,\n",
       " -0.0022462436463683844,\n",
       " -0.0019422534387558699,\n",
       " -0.001967957243323326,\n",
       " -0.0011308600660413504,\n",
       " -0.0019250730983912945,\n",
       " -0.0012322540860623121,\n",
       " -0.0015379609540104866,\n",
       " -0.0020235779229551554,\n",
       " -0.0013343732571229339,\n",
       " -0.0010509322164580226,\n",
       " -0.0010824351338669658,\n",
       " -0.00138756912201643,\n",
       " -0.0009210365824401379,\n",
       " -0.0016330154612660408,\n",
       " -0.001225234242156148,\n",
       " -0.0006276129279285669,\n",
       " -0.00022968593111727387,\n",
       " 0.0002770062128547579,\n",
       " -0.00028079035109840333,\n",
       " -0.000401397148380056,\n",
       " -0.00012247390986885875,\n",
       " 0.0003318136732559651,\n",
       " -0.00011841882223961875,\n",
       " -0.0001451596908736974,\n",
       " -7.853016722947359e-05,\n",
       " -0.0006748618325218558,\n",
       " -4.463869845494628e-05,\n",
       " -0.0012408837210386992,\n",
       " -0.0018864292651414871,\n",
       " -0.0018978853477165103,\n",
       " -0.0017069755122065544,\n",
       " -0.0012572570703923702,\n",
       " -0.0016932673752307892,\n",
       " -0.0018605557270348072,\n",
       " -0.002607472939416766,\n",
       " -0.001898684073239565,\n",
       " -0.0016888483660295606,\n",
       " -0.0021601556800305843,\n",
       " -0.002791411941871047,\n",
       " -0.00379843357950449,\n",
       " -0.003545518731698394,\n",
       " -0.00351994251832366,\n",
       " -0.0038822260685265064,\n",
       " -0.004007349722087383,\n",
       " -0.004030285868793726,\n",
       " -0.0038126942235976458,\n",
       " -0.0036338663194328547,\n",
       " -0.0035667307674884796,\n",
       " -0.004346292465925217,\n",
       " -0.003904609242454171,\n",
       " -0.003996466286480427,\n",
       " -0.004677140153944492,\n",
       " -0.0043838354758918285,\n",
       " -0.0047539048828184605,\n",
       " -0.004334853962063789,\n",
       " -0.004395096097141504,\n",
       " -0.003950601443648338,\n",
       " -0.004518235567957163,\n",
       " -0.004389614798128605,\n",
       " -0.003954422660171986,\n",
       " -0.003927287645637989,\n",
       " -0.0034077295567840338,\n",
       " -0.0036125234328210354,\n",
       " -0.0033973264507949352,\n",
       " -0.0034650363959372044,\n",
       " -0.003760404884815216,\n",
       " -0.0033474545925855637,\n",
       " -0.0034235776402056217,\n",
       " -0.0041315024718642235,\n",
       " -0.004235181491822004,\n",
       " -0.004531047772616148,\n",
       " -0.004883552901446819,\n",
       " -0.005166310351341963,\n",
       " -0.004850745666772127,\n",
       " -0.0054355585016310215,\n",
       " -0.004378668498247862,\n",
       " -0.004702772479504347,\n",
       " -0.005197521764785051,\n",
       " -0.004309854004532099,\n",
       " -0.005001272540539503,\n",
       " -0.004988518077880144,\n",
       " -0.005277745891362429,\n",
       " -0.005418033804744482,\n",
       " -0.004803468007594347,\n",
       " -0.004243161529302597,\n",
       " -0.0033293627202510834,\n",
       " -0.0033822644036263227,\n",
       " -0.0025107122492045164,\n",
       " -0.001936206128448248,\n",
       " -0.0020061631221324205,\n",
       " -0.0009249910362996161,\n",
       " -0.001579759642481804,\n",
       " -0.000982216908596456,\n",
       " -0.0008750163251534104,\n",
       " -0.0006682593957521021,\n",
       " -0.0006441593286581337,\n",
       " -0.0001653871004236862,\n",
       " -0.0002937547105830163,\n",
       " 5.053079439676367e-05,\n",
       " 2.2604106561630033e-05,\n",
       " -0.0011388604762032628,\n",
       " -0.001208839239552617,\n",
       " -0.001681676134467125,\n",
       " -0.0016840308671817183,\n",
       " -0.0021672972943633795,\n",
       " -0.001865222118794918,\n",
       " -0.0028954099398106337,\n",
       " -0.00240370468236506,\n",
       " -0.0028429552912712097,\n",
       " -0.003326650243252516,\n",
       " -0.002612985670566559,\n",
       " -0.003177426988258958,\n",
       " -0.0034635625779628754,\n",
       " -0.003247971413657069,\n",
       " -0.0032514105550944805,\n",
       " -0.0032974903006106615,\n",
       " -0.0028525670059025288,\n",
       " -0.002585943089798093,\n",
       " -0.002585442503914237,\n",
       " -0.0024154065176844597,\n",
       " -0.0021702463272958994,\n",
       " -0.0027124504558742046,\n",
       " -0.0021499949507415295,\n",
       " -0.0032001726794987917,\n",
       " -0.0030715714674443007,\n",
       " -0.0035866391845047474,\n",
       " -0.00355838262476027,\n",
       " -0.002403797348961234,\n",
       " -0.003401892725378275,\n",
       " -0.002917729550972581,\n",
       " -0.0035496570635586977,\n",
       " -0.0034284277353435755,\n",
       " -0.003853117348626256,\n",
       " -0.003945997450500727,\n",
       " -0.003693028585985303,\n",
       " -0.004287899471819401,\n",
       " -0.003345397999510169,\n",
       " -0.0032329275272786617,\n",
       " -0.003473876276984811,\n",
       " -0.0032675424590706825,\n",
       " -0.004285313654690981,\n",
       " -0.0049674599431455135,\n",
       " -0.003713454119861126,\n",
       " -0.004458093550056219,\n",
       " -0.003685970790684223,\n",
       " -0.003264141036197543,\n",
       " -0.0036574089899659157,\n",
       " -0.00325775402598083,\n",
       " -0.0033766506239771843,\n",
       " -0.0032659408170729876,\n",
       " -0.0033621948678046465,\n",
       " -0.002765235723927617,\n",
       " -0.003238434437662363,\n",
       " -0.0027042212896049023,\n",
       " -0.0032728423830121756,\n",
       " -0.003593598725274205,\n",
       " -0.0032133085187524557,\n",
       " -0.00418887659907341,\n",
       " -0.004176183138042688,\n",
       " -0.003780759172514081,\n",
       " -0.004671670962125063,\n",
       " -0.004160784184932709,\n",
       " -0.0036615529097616673,\n",
       " -0.004260134883224964,\n",
       " -0.0044203693978488445,\n",
       " -0.004941383842378855,\n",
       " -0.0053974175825715065,\n",
       " -0.0053130947053432465,\n",
       " -0.005311266984790564,\n",
       " -0.005736664403229952,\n",
       " -0.005091129336506128,\n",
       " -0.005935081280767918,\n",
       " -0.006201643962413073,\n",
       " -0.006870944052934647,\n",
       " -0.006689959205687046,\n",
       " -0.006585069932043552,\n",
       " -0.006130404304713011,\n",
       " -0.0059643955901265144,\n",
       " -0.007164855487644672,\n",
       " -0.006602048873901367,\n",
       " -0.007500837557017803,\n",
       " -0.007017411757260561,\n",
       " -0.006855481769889593,\n",
       " -0.006724751088768244,\n",
       " -0.007197449915111065,\n",
       " -0.007267475128173828,\n",
       " -0.006760450545698404,\n",
       " -0.007227837573736906,\n",
       " -0.006304871290922165,\n",
       " -0.006844962481409311,\n",
       " -0.006712241098284721,\n",
       " -0.006518519949167967,\n",
       " -0.007018835749477148,\n",
       " -0.007238240912556648,\n",
       " -0.006528239697217941,\n",
       " -0.005781665910035372,\n",
       " -0.005963348317891359,\n",
       " -0.00491579994559288,\n",
       " -0.006373847834765911,\n",
       " -0.006127582397311926,\n",
       " -0.006186335813254118,\n",
       " -0.007015758194029331,\n",
       " -0.0055434927344322205,\n",
       " -0.006358606740832329,\n",
       " -0.005654211156070232,\n",
       " -0.005348356906324625,\n",
       " -0.005577839445322752,\n",
       " -0.00558866374194622,\n",
       " -0.005449847783893347,\n",
       " -0.005260995589196682,\n",
       " -0.005604556296020746,\n",
       " -0.005641518626362085,\n",
       " -0.006489612627774477,\n",
       " -0.006773851346224546,\n",
       " -0.0069195665419101715,\n",
       " -0.00682993046939373,\n",
       " -0.006618215702474117,\n",
       " -0.007513735443353653,\n",
       " -0.008122150786221027,\n",
       " -0.00794054102152586,\n",
       " -0.009299675934016705,\n",
       " -0.009030547924339771,\n",
       " -0.009303785860538483,\n",
       " -0.008750618435442448,\n",
       " -0.008401179686188698,\n",
       " -0.00823398120701313,\n",
       " -0.00759402709081769,\n",
       " -0.009002791717648506,\n",
       " -0.007900592871010303,\n",
       " -0.008669238537549973,\n",
       " -0.007443456910550594,\n",
       " -0.007181539200246334,\n",
       " -0.007528021465986967,\n",
       " -0.007341187447309494,\n",
       " -0.007682107388973236,\n",
       " -0.0073342276737093925,\n",
       " -0.007054094225168228,\n",
       " -0.006186957936733961,\n",
       " -0.006676365155726671,\n",
       " -0.006261132191866636,\n",
       " -0.007041082251816988,\n",
       " -0.00624242564663291,\n",
       " -0.005838986951857805,\n",
       " -0.005713917780667543,\n",
       " -0.0058096409775316715,\n",
       " -0.006303337402641773,\n",
       " -0.006956951692700386,\n",
       " -0.007350305560976267,\n",
       " -0.0061422353610396385,\n",
       " -0.006619167514145374,\n",
       " -0.005995174404233694,\n",
       " -0.005735717713832855,\n",
       " -0.006016900762915611,\n",
       " -0.005399414338171482,\n",
       " -0.0062171039171516895,\n",
       " -0.005903895944356918,\n",
       " -0.004793770611286163,\n",
       " -0.0046015032567083836,\n",
       " -0.003994027152657509,\n",
       " -0.0037945404183119535,\n",
       " -0.004402827937155962,\n",
       " -0.004120138008147478,\n",
       " -0.0027178702875971794,\n",
       " -0.0032924471888691187,\n",
       " -0.00271376664750278,\n",
       " -0.002415646566078067,\n",
       " -0.0032360421027988195,\n",
       " -0.002278692787513137,\n",
       " -0.0017790672136470675,\n",
       " -0.0014536528615280986,\n",
       " -0.0014982857974246144,\n",
       " -0.0016542815137654543,\n",
       " -0.0026426268741488457,\n",
       " -0.002383837243542075,\n",
       " -0.0026462955866008997,\n",
       " -0.0032505705021321774,\n",
       " -0.003132225014269352,\n",
       " -0.0031455745920538902,\n",
       " -0.0014160153223201632,\n",
       " -0.001519722049124539,\n",
       " -0.0017598209669813514,\n",
       " -0.0014642992755398154,\n",
       " -0.0019188453443348408,\n",
       " -0.0019253178033977747,\n",
       " -0.0015596619341522455,\n",
       " -0.001499110832810402,\n",
       " -0.0016226500738412142,\n",
       " -0.0018220965284854174,\n",
       " -0.0015203568618744612,\n",
       " -0.000797044369392097,\n",
       " -0.000950909685343504,\n",
       " -3.778824248001911e-05,\n",
       " -0.0003474423137959093,\n",
       " -0.00019348363275639713,\n",
       " 0.0007066106190904975,\n",
       " 0.0007871767156757414,\n",
       " 0.0012063729809597135,\n",
       " 0.000906227738596499,\n",
       " 0.0006389382178895175,\n",
       " 0.00020221176964696497,\n",
       " 0.0005638342117890716,\n",
       " 0.0004667559405788779,\n",
       " 0.0009432404767721891,\n",
       " 0.001723405090160668,\n",
       " 0.0023275897838175297,\n",
       " 0.002757391892373562,\n",
       " 0.002995024900883436,\n",
       " 0.002025935333222151,\n",
       " 0.0010627395240589976,\n",
       " 0.0018234754679724574,\n",
       " 0.001193914096802473,\n",
       " 0.0018990362295880914,\n",
       " 0.0019023492932319641,\n",
       " 0.0015705415280535817,\n",
       " 0.001197442994453013,\n",
       " 0.0010753592941910028,\n",
       " 0.001643731608055532,\n",
       " 0.0009062124881893396,\n",
       " 0.0003703522670548409,\n",
       " -0.00017673178808763623,\n",
       " 0.00042535687680356205,\n",
       " -0.00043235503835603595,\n",
       " -0.0009579519391991198,\n",
       " -0.0005710101104341447,\n",
       " -0.0018291398882865906,\n",
       " -0.002011652337387204,\n",
       " -0.0022662607952952385,\n",
       " -0.0023884701076895,\n",
       " -0.0025072956923395395,\n",
       " -0.002998679643496871,\n",
       " -0.002822554437443614,\n",
       " -0.0035488440189510584,\n",
       " -0.002517704851925373,\n",
       " -0.0031977747566998005,\n",
       " -0.0027397170197218657,\n",
       " -0.0021214978769421577,\n",
       " -0.003110271878540516,\n",
       " -0.0013257716782391071,\n",
       " -0.0026139221154153347,\n",
       " -0.0026368319522589445,\n",
       " -0.0026746017392724752,\n",
       " -0.002191410632804036,\n",
       " -0.0014771593268960714,\n",
       " -0.0013927628751844168,\n",
       " -0.0010732306400313973,\n",
       " -0.0017169046914204955,\n",
       " -0.001395698986016214,\n",
       " -0.0030192076228559017,\n",
       " -0.001554864807985723,\n",
       " -0.0018282579258084297,\n",
       " -0.0016627181321382523,\n",
       " -0.00022479728795588017,\n",
       " -0.0016754737589508295,\n",
       " -0.0006645325920544565,\n",
       " -0.0009238724014721811,\n",
       " -0.0016969448188319802,\n",
       " -0.0026277799624949694,\n",
       " -0.002376081421971321,\n",
       " -0.0011570981005206704,\n",
       " -0.0010479317279532552,\n",
       " -0.0006594200967811048,\n",
       " -0.0003040430601686239,\n",
       " -0.0012742722174152732,\n",
       " -0.0008143773302435875,\n",
       " -0.0007001592894084752,\n",
       " -0.0016007235972210765,\n",
       " -0.0004149882006458938,\n",
       " -0.000540223263669759,\n",
       " -1.5958245057845488e-05,\n",
       " 7.194447243819013e-05,\n",
       " 0.0001666336611378938,\n",
       " 0.0005920260446146131,\n",
       " 7.860181358410046e-05,\n",
       " 0.0002423820405965671,\n",
       " 0.0003525171196088195,\n",
       " 0.0005832488532178104,\n",
       " 0.0006273541366681457,\n",
       " 0.0003022165910806507,\n",
       " -0.0005683055496774614,\n",
       " -0.0004304916365072131,\n",
       " -0.0003325556463096291,\n",
       " -0.0005921284318901598,\n",
       " 3.4499753382988274e-05,\n",
       " 0.0001358943263767287,\n",
       " 0.0011093978537246585,\n",
       " 8.883002010406926e-05,\n",
       " 1.6276415408356115e-05,\n",
       " -0.0007151200552470982,\n",
       " -0.0008064073044806719,\n",
       " -0.0005744158406741917,\n",
       " -0.0006365475128404796,\n",
       " 0.0009101290488615632,\n",
       " -0.0007368862861767411,\n",
       " 0.002180373528972268,\n",
       " -0.00031780966673977673,\n",
       " -0.0014667699579149485,\n",
       " -0.0006764912395738065,\n",
       " -0.00394048634916544,\n",
       " -0.0020730963442474604,\n",
       " -0.002981941681355238,\n",
       " -0.0019969376735389233,\n",
       " -0.003770176088437438,\n",
       " -0.002988141728565097,\n",
       " -0.0023858235217630863,\n",
       " -0.0045993635430932045,\n",
       " -0.0009428386692889035,\n",
       " -0.003002704819664359,\n",
       " -0.002093501156195998,\n",
       " -0.0022077136673033237,\n",
       " -0.0028320804703980684,\n",
       " -0.002647003624588251,\n",
       " -0.0032097704242914915,\n",
       " -0.002567979507148266,\n",
       " -0.003026932245120406,\n",
       " -0.0027546407654881477,\n",
       " -0.0035823085345327854,\n",
       " -0.002036892808973789,\n",
       " -0.003195998026058078,\n",
       " -0.0035430786665529013,\n",
       " -0.002289049094542861,\n",
       " -0.0028360134456306696,\n",
       " -0.0031393824610859156,\n",
       " -0.0026151195634156466,\n",
       " -0.00356318149715662,\n",
       " -0.004097268916666508,\n",
       " -0.0028438041917979717,\n",
       " -0.002438967814669013,\n",
       " -0.003533758921548724,\n",
       " -0.002727081999182701,\n",
       " -0.0037862886674702168,\n",
       " -0.004539885558187962,\n",
       " -0.0031072755809873343,\n",
       " -0.004042120650410652,\n",
       " -0.004467939492315054,\n",
       " -0.00458563445135951,\n",
       " -0.0041968137957155704,\n",
       " -0.004633097443729639,\n",
       " -0.0034252628684043884,\n",
       " -0.0033591303508728743,\n",
       " -0.0038769321981817484,\n",
       " -0.004104882013052702,\n",
       " -0.004245973192155361,\n",
       " -0.00470689544454217,\n",
       " -0.0038530025631189346,\n",
       " -0.0047944993712008,\n",
       " -0.0052430396899580956,\n",
       " -0.004421768710017204,\n",
       " -0.005352470558136702,\n",
       " -0.0044960216619074345,\n",
       " -0.0052796099334955215,\n",
       " -0.00451658433303237,\n",
       " -0.004549971781671047,\n",
       " -0.004767114296555519,\n",
       " -0.004961741156876087,\n",
       " -0.004748188890516758,\n",
       " -0.005704415030777454,\n",
       " -0.0053783440962433815,\n",
       " -0.004930966068059206,\n",
       " -0.006780044641345739,\n",
       " -0.005344766657799482,\n",
       " -0.00482402415946126,\n",
       " -0.005459388718008995,\n",
       " -0.0045884051360189915,\n",
       " -0.00436848821118474,\n",
       " -0.004583977162837982,\n",
       " -0.0035887102130800486,\n",
       " -0.003427796997129917,\n",
       " -0.0032875018659979105,\n",
       " -0.00411263620480895,\n",
       " -0.004032035358250141,\n",
       " -0.004361798521131277,\n",
       " -0.0041714864782989025,\n",
       " -0.004441246390342712,\n",
       " -0.004556000232696533,\n",
       " -0.0036390216555446386,\n",
       " -0.004783868324011564,\n",
       " -0.004401182755827904,\n",
       " -0.005321687553077936,\n",
       " -0.005287358071655035,\n",
       " -0.005692020989954472,\n",
       " -0.00524826580658555,\n",
       " -0.005454058758914471,\n",
       " -0.005935679655522108,\n",
       " -0.005296414718031883,\n",
       " -0.006337209604680538,\n",
       " -0.00545531464740634,\n",
       " -0.005373308900743723,\n",
       " -0.004599396605044603,\n",
       " -0.0052603380754590034,\n",
       " -0.005367882549762726,\n",
       " -0.005222346168011427,\n",
       " -0.005426236893981695,\n",
       " -0.004200480412691832,\n",
       " -0.0044632116332650185,\n",
       " -0.004640651401132345,\n",
       " -0.004705166909843683,\n",
       " -0.005316657479852438,\n",
       " -0.004085886292159557,\n",
       " -0.0032460056245326996,\n",
       " -0.003515183227136731,\n",
       " -0.0023300040047615767,\n",
       " -0.0026807566173374653,\n",
       " -0.002637702040374279,\n",
       " -0.002143390476703644,\n",
       " -0.002535712905228138,\n",
       " -0.0019929981790483,\n",
       " -0.0011877011274918914,\n",
       " -0.0010105245746672153,\n",
       " -0.0007323174504563212,\n",
       " -0.0007205823785625398,\n",
       " -0.001539778895676136,\n",
       " -0.0019482685020193458,\n",
       " -0.0007699198322370648,\n",
       " -0.0013888066168874502,\n",
       " -0.0009763782727532089,\n",
       " -0.0007515327888540924,\n",
       " -0.0022355986293405294,\n",
       " -0.0014732519630342722,\n",
       " -0.002620960120111704,\n",
       " -0.0032333265990018845,\n",
       " -0.004090263042598963,\n",
       " -0.003694054903462529,\n",
       " -0.0039023100398480892,\n",
       " -0.004490052815526724,\n",
       " -0.003736382583156228,\n",
       " -0.004627457354217768,\n",
       " -0.003726865164935589,\n",
       " -0.003957238048315048,\n",
       " -0.004162905737757683,\n",
       " -0.004828477278351784,\n",
       " -0.004434889182448387,\n",
       " -0.004194751847535372,\n",
       " -0.004254201892763376,\n",
       " -0.0033835554495453835,\n",
       " -0.0030670117121189833,\n",
       " -0.002936241216957569,\n",
       " -0.0033235144801437855,\n",
       " -0.002978751203045249,\n",
       " -0.0036997669376432896,\n",
       " -0.0036577091086655855,\n",
       " -0.003913594875484705,\n",
       " -0.0024969540536403656,\n",
       " -0.0024124777410179377,\n",
       " -0.0023699807934463024,\n",
       " -0.001668538898229599,\n",
       " -0.0027751601301133633,\n",
       " -0.001821241108700633,\n",
       " -0.0017452863976359367,\n",
       " -0.0021404416766017675,\n",
       " -0.0019974440801888704,\n",
       " -0.0014479272067546844,\n",
       " -0.0025543714873492718,\n",
       " -0.0019453156273812056,\n",
       " -0.0015982571057975292,\n",
       " -0.0023510539904236794,\n",
       " -0.0011858046054840088,\n",
       " -0.0011880849488079548,\n",
       " -0.0011267830850556493,\n",
       " -0.0012034605024382472,\n",
       " 4.754773271997692e-06,\n",
       " -0.0012326689902693033,\n",
       " -0.0005375673645175993,\n",
       " 0.0006482902099378407,\n",
       " 0.000681772013194859,\n",
       " 0.0017021371750161052,\n",
       " 0.0004324567271396518,\n",
       " 0.0015967957442626357,\n",
       " -0.0007902607321739197,\n",
       " -0.0002929411130025983,\n",
       " -0.000512654019985348,\n",
       " -0.0008667955989949405,\n",
       " 0.0009459964348934591,\n",
       " 0.0005375908222049475,\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data[0]['array']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmetation(RIR applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4160])\n"
     ]
    }
   ],
   "source": [
    "rir_raw,_ = librosa.load('./room_component.wav',sr)\n",
    "rir = torch.from_numpy(rir_raw.reshape(1,-1))\n",
    "print(rir.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rir_applied(batch):\n",
    "\n",
    "    speech = torch.from_numpy(np.array(batch['array'],dtype=np.float32).reshape(1,-1))\n",
    "\n",
    "    speech_ = torch.nn.functional.pad(speech, (rir.shape[1] - 1, 0))\n",
    "#     print(speech.dtype)\n",
    "#     print(speech_.dtype)\n",
    "#     print(rir.dtype)\n",
    "    augmented = torch.nn.functional.conv1d(speech_[None, ...], rir[None, ...])[0]\n",
    "    batch['array'] = augmented.reshape(-1)\n",
    "    return batch\n",
    "\n",
    "def fast_stretching(batch):\n",
    "    array = np.array(batch['array'],dtype=np.float32)\n",
    "    batch['array'] = librosa.effects.time_stretch(array,0.8)\n",
    "    return batch\n",
    "\n",
    "def too_fast_stretching(batch):\n",
    "    array = np.array(batch['array'],dtype=np.float32)\n",
    "    batch['array'] = librosa.effects.time_stretch(array,0.5)\n",
    "    return batch\n",
    "\n",
    "def slow_stretching(batch):\n",
    "    array = np.array(batch['array'],dtype=np.float32)\n",
    "    batch['array'] = librosa.effects.time_stretch(array,1.2)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "475edc9d23d9420e8ee218e97e85b37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rir_applied_audio_data = audio_data.map(rir_applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "410459bbfa604a2f832a88944eddebb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fast_stretching_data = audio_data.map(fast_stretching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a4eacfba2d41ec8ec8e4d2c619f0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "too_fast_stretching_data = audio_data.map(too_fast_stretching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZiv4zqyt2cY"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "AscOxzgUsb50"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "\n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(batch[\"array\"], sampling_rate=16000).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa1e8d4896ff4f799a235f8cf7dd9d19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7253e07ebcb466e8879233e1f519c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e853dc7437744a0a16f7b68e31e6008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f420621ab9c04fe6befbde538e1f54a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_list = [\n",
    "    audio_data,\n",
    "    rir_applied_audio_data,\n",
    "    fast_stretching_data,\n",
    "    too_fast_stretching_data\n",
    "]\n",
    "prepare_ds_list = []\n",
    "for ds in ds_list:\n",
    "    prepare_ds_list.append(ds.map(\n",
    "        prepare_dataset,\n",
    "        remove_columns=ds.column_names,\n",
    "        # num_proc=2\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = torch.utils.data.ConcatDataset(prepare_ds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StCtCQxDtuY3"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUTqiRY-tpXZ"
   },
   "source": [
    "## Set-up Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nTlewiOzsyqR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.cuda.HalfTensor]]]) -> Dict[str, torch.cuda.HalfTensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "WmfIPs18tGQb"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "vJjfNy9-tJM6"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Audio\n",
    "\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "03mNNUfNthSZ"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vgRoeQHvTqk"
   },
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkpoint-3000'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir=\"./wav2vec2-large-xlsr-ko-demo\"\n",
    "model_list = os.listdir(output_dir)\n",
    "model_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Iyv4qaclue6n"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    os.path.join(output_dir,model_list[0]), \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaYmsSutuv26"
   },
   "source": [
    "XLSR-Wav2Vec2의 첫 번째 구성 요소는 원시 음성 신호에서 음향적으로 의미가 있지만 문맥적으로 독립적인 기능을 추출하는 데 사용되는 CNN 계층 스택으로 구성됩니다.  \n",
    "모델의 이 부분은 사전 교육 중에 이미 충분히 훈련되었으며 논문에 명시된 바와 같이 더 이상 미세 조정할 필요가 없습니다. 따라서 특징 추출 부분의 모든 파라미터에 대해 require_grad를 False로 설정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "5VX8z6PpuhqG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI_server\\Anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\models\\wav2vec2\\modeling_wav2vec2.py:1677: FutureWarning: The method `freeze_feature_extractor` is deprecated and will be removed in Transformers v5.Please use the equivalent `freeze_feature_encoder` method instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAfoHUk9vGxd"
   },
   "source": [
    "메모리를 절약하기 위해 그라데이션 체크포인팅을 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wZm6in_2vAIN"
   },
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-aJNQplvQgn"
   },
   "source": [
    "## TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "-LuuwoeMvOnV"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-ko-demo\",\n",
    "  output_dir=output_dir,\n",
    "  group_by_length=True,\n",
    "  per_device_train_batch_size=8,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=20,\n",
    "  fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=2,\n",
    "#   auto_find_batch_size=True, # need -> pip install accelerate\n",
    "  load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "6vhFC0BdvcOu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "ds_size = len(augmented_data)\n",
    "train_size = int(ds_size*0.8)\n",
    "val_size = ds_size - train_size\n",
    "train_ds, val_ds = random_split(augmented_data,[train_size,val_size])\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHGNj1NSvsFk"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_memory_allocated : 1262210048\n",
      "max_memory_reserved : 1264582656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI_server\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\cuda\\memory.py:274: FutureWarning: torch.cuda.reset_max_memory_allocated now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n",
      "C:\\Users\\AI_server\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\cuda\\memory.py:300: FutureWarning: torch.cuda.reset_max_memory_cached now calls torch.cuda.reset_peak_memory_stats, which resets /all/ peak memory stats.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "# display(torch.cuda.memory_stats(\"cuda\"))\n",
    "torch.cuda.reset_max_memory_allocated(\"cuda\")\n",
    "torch.cuda.reset_max_memory_cached(\"cuda\")\n",
    "\n",
    "print(\"max_memory_allocated :\",\n",
    "      torch.cuda.max_memory_allocated(\"cuda\"))\n",
    "print(\"max_memory_reserved :\",\n",
    "      torch.cuda.max_memory_reserved(\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.memory_allocated(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "a-rJ8fokvjJb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI_server\\Anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 320\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='400' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [400/400 06:31, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.047755</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.016672</td>\n",
       "      <td>0.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.043900</td>\n",
       "      <td>0.033131</td>\n",
       "      <td>0.146667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.039100</td>\n",
       "      <td>0.028646</td>\n",
       "      <td>0.340000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 80\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-300] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200 (score: 0.016671936959028244).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=400, training_loss=0.4334152438491583, metrics={'train_runtime': 397.4078, 'train_samples_per_second': 16.104, 'train_steps_per_second': 1.007, 'total_flos': 9.023015986227489e+17, 'train_loss': 0.4334152438491583, 'epoch': 20.0})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxpIR_X8w3Pq"
   },
   "source": [
    "CTC 손실을 사용하여 더 큰 데이터 세트에서 더 큰 모델을 미세 조정하려면 [여기서](https://github.com/huggingface/transformers/tree/master/examples/pytorch/speech-recognition#connectionist-temporal-classification-without-language-model-ctc-wo-lm) 공식 음성 인식 예를 살펴봐야 한다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00.XLSR - Wav2Vec2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "STT",
   "language": "python",
   "name": "stt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "19631f30805cf65d5465564d75f0fe7c05dee5c1f7be198222dbe754da644e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
