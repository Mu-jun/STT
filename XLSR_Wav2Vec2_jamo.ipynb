{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import transformers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./dataset/csv/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-0f216d6397fe291f\n",
      "Reusing dataset csv (C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    }
   ],
   "source": [
    "all_data = load_dataset('csv',data_files=os.path.join(data_path,'order_speech_ko1000_000.csv'),sep='\\t',split='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "id": "G34Hj6BgnK3L"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from unicode import split_syllables, join_jamos\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"\\“\\%\\‘\\”\\�]'\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower() + \" \"\n",
    "    batch[\"text\"] = split_syllables(batch[\"text\"])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f83e215b608199a6.arrow\n"
     ]
    }
   ],
   "source": [
    "remove_spectial_char_data = all_data.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLCZvETJuFaO"
   },
   "source": [
    "## Create Wav2Vec2CTCTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "YJUUl9lnryU-"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2CTCTokenizer\n",
    "\n",
    "tokenizer = Wav2Vec2CTCTokenizer(\"./vocab_jamos.json\",\n",
    "                                 unk_token=\"<unk>\",\n",
    "                                 pad_token=\"<pad>\",\n",
    "                                 word_delimiter_token=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gCtrdRsuuDix"
   },
   "source": [
    "## Create XLSR-Wav2Vec2 Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "id": "O0vdrkhKr8D1"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2FeatureExtractor\n",
    "\n",
    "feature_extractor = Wav2Vec2FeatureExtractor(feature_size=1,\n",
    "                                             sampling_rate=16000,\n",
    "                                             padding_value=0.0,\n",
    "                                             do_normalize=True,\n",
    "                                             return_attention_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "id": "fY_Qm1dpsE78"
   },
   "outputs": [],
   "source": [
    "from transformers import Wav2Vec2Processor\n",
    "\n",
    "processor = Wav2Vec2Processor(feature_extractor=feature_extractor,\n",
    "                              tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "KTUahP1PsL3g"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "9tMSA3xKsVma"
   },
   "outputs": [],
   "source": [
    "# processor.save_pretrained(\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add audio array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(batch):\n",
    "#     batch['array'],_ = librosa.load('./dataset/audio/'+batch['filename'],sr=16000)\n",
    "    batch['array'] = np.array(batch['array'][1:-1].split(',')).astype(np.float32)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-6fd2796a774ac563.arrow\n"
     ]
    }
   ],
   "source": [
    "audio_data = remove_spectial_char_data.map(load_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio_data[0]['array'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.1133459605627838e-12,\n",
       " -1.0502000744733175e-12,\n",
       " 2.2163180578987918e-12,\n",
       " -1.5682264514760291e-12,\n",
       " -1.5212372919508332e-13,\n",
       " 4.4247804205366226e-12,\n",
       " -1.2672983322470355e-11,\n",
       " 2.656890679686441e-11,\n",
       " -4.7877282000063914e-11,\n",
       " 7.819626196559071e-11,\n",
       " -1.1858666826292108e-10,\n",
       " 1.6909297573253212e-10,\n",
       " -2.2817649159012632e-10,\n",
       " 2.91835583476896e-10,\n",
       " -3.552248772908939e-10,\n",
       " 4.067994274770115e-10,\n",
       " -4.344273552003841e-10,\n",
       " 4.197922565118972e-10,\n",
       " -3.445344287644758e-10,\n",
       " 1.849441849666178e-10,\n",
       " 8.215064739580669e-11,\n",
       " -4.78959205629792e-10,\n",
       " 1.023487516960131e-09,\n",
       " -1.728527765365584e-09,\n",
       " 2.5924540292265874e-09,\n",
       " -3.6031813088754916e-09,\n",
       " 4.728607727599865e-09,\n",
       " -5.9183116185579365e-09,\n",
       " 7.0954735420514226e-09,\n",
       " -8.165113918323641e-09,\n",
       " 9.004995860095732e-09,\n",
       " -9.479230733688837e-09,\n",
       " 9.433169800843189e-09,\n",
       " -8.711409371642276e-09,\n",
       " 7.156912840144969e-09,\n",
       " -4.631779848551787e-09,\n",
       " 1.0228798918987536e-09,\n",
       " 3.738064524583251e-09,\n",
       " -9.669823164415448e-09,\n",
       " 1.6719576834134386e-08,\n",
       " -2.4763238570812973e-08,\n",
       " 3.358802658226523e-08,\n",
       " -4.2899323204892426e-08,\n",
       " 5.2311136755633925e-08,\n",
       " -6.136136931900182e-08,\n",
       " 6.95132342798388e-08,\n",
       " -7.617315134211822e-08,\n",
       " 8.07050000162235e-08,\n",
       " -8.244801819046188e-08,\n",
       " 8.072798607372533e-08,\n",
       " -7.48695967445201e-08,\n",
       " 6.41925836930568e-08,\n",
       " -4.79887098947529e-08,\n",
       " 2.5471173614732834e-08,\n",
       " 4.344962611924075e-09,\n",
       " -4.285755395017077e-08,\n",
       " 9.230814157490386e-08,\n",
       " -1.566494489679826e-07,\n",
       " 2.434764212466689e-07,\n",
       " -3.687780463224044e-07,\n",
       " 5.707519221687107e-07,\n",
       " -9.608891105017392e-07,\n",
       " 2.011694959946908e-06,\n",
       " -1.982389403565321e-05,\n",
       " -3.381989517947659e-05,\n",
       " -2.808686622302048e-05,\n",
       " -3.378229303052649e-05,\n",
       " -9.737765140016563e-06,\n",
       " 2.1359337551984936e-06,\n",
       " -1.1359037443980924e-06,\n",
       " 7.996309818736336e-07,\n",
       " -6.628220035054255e-07,\n",
       " 6.278405066950654e-07,\n",
       " -6.895929800521117e-07,\n",
       " 9.314210274169454e-07,\n",
       " -1.7845843558461638e-06,\n",
       " 9.060990123543888e-06,\n",
       " 3.529813693603501e-05,\n",
       " 1.920880276884418e-05,\n",
       " -5.682449000232737e-07,\n",
       " 3.1214949558489025e-05,\n",
       " 2.1330506569938734e-05,\n",
       " -3.5850723634212045e-06,\n",
       " 3.0046901429159334e-06,\n",
       " -3.8449352359748445e-06,\n",
       " 1.159538805950433e-05,\n",
       " 3.129951801383868e-05,\n",
       " 3.2153348001884297e-05,\n",
       " 1.0317194210074376e-05,\n",
       " 2.7762685022025835e-06,\n",
       " 2.664223575266078e-05,\n",
       " 2.9767035812255926e-05,\n",
       " 3.17157682729885e-05,\n",
       " 2.942928040283732e-05,\n",
       " 3.182423097314313e-05,\n",
       " 2.9266906494740397e-05,\n",
       " 3.223313615308143e-05,\n",
       " 2.7312880774843507e-05,\n",
       " 4.779694336320972e-06,\n",
       " 2.7140618840348907e-05,\n",
       " 3.252692476962693e-05,\n",
       " 2.8826303605455905e-05,\n",
       " 3.2435240427730605e-05,\n",
       " 2.8600474252016284e-05,\n",
       " 3.288454536232166e-05,\n",
       " 2.7803032935480587e-05,\n",
       " 3.462359381956048e-05,\n",
       " 1.869481275207363e-05,\n",
       " -4.887683076049143e-07,\n",
       " -1.0743377742983284e-06,\n",
       " 3.350684892211575e-06,\n",
       " 2.5267188902944326e-05,\n",
       " 4.555170107778395e-06,\n",
       " -3.8213406696741e-06,\n",
       " 5.353847882361151e-06,\n",
       " -2.4609977117506787e-05,\n",
       " -2.0716741346404888e-05,\n",
       " 9.432915817342291e-07,\n",
       " 2.1732271306973416e-06,\n",
       " -2.1873462173971348e-05,\n",
       " -2.350886097701732e-05,\n",
       " 4.31493435826269e-06,\n",
       " -3.023999397555599e-06,\n",
       " 4.434088623384014e-06,\n",
       " 1.953521314135287e-05,\n",
       " -5.827238965139259e-06,\n",
       " -7.527671186835505e-06,\n",
       " 1.467637389396259e-06,\n",
       " -8.547775678380276e-07,\n",
       " 1.1431337043177336e-05,\n",
       " -7.0720207077101804e-06,\n",
       " -6.188232418935513e-06,\n",
       " 4.909134077024646e-06,\n",
       " -2.231733378721401e-05,\n",
       " -3.130655022687279e-05,\n",
       " -3.094847852480598e-05,\n",
       " -2.981682882818859e-05,\n",
       " -3.166837996104732e-05,\n",
       " -3.9454509533243254e-05,\n",
       " -3.232599192415364e-05,\n",
       " -2.817759377649054e-05,\n",
       " -4.579059896059334e-05,\n",
       " -4.842226189794019e-05,\n",
       " -2.937968929472845e-05,\n",
       " -3.085625940002501e-05,\n",
       " -3.0776544008404016e-05,\n",
       " -3.014531648659613e-05,\n",
       " -3.128416938125156e-05,\n",
       " -2.9688220820389688e-05,\n",
       " -3.180045314365998e-05,\n",
       " -2.8882881451863796e-05,\n",
       " -3.4407261409796774e-05,\n",
       " -4.1713385144248605e-05,\n",
       " -3.8838115870021284e-05,\n",
       " -2.7166448489879258e-05,\n",
       " -3.49513502442278e-05,\n",
       " -1.7814327293308452e-05,\n",
       " -1.653943218116183e-05,\n",
       " -1.553654692543205e-05,\n",
       " 1.2685515685006976e-05,\n",
       " -1.7646588048592093e-06,\n",
       " 1.5318621535698185e-06,\n",
       " -1.548784439364681e-06,\n",
       " 1.8431230728310766e-06,\n",
       " -2.8600188670679927e-06,\n",
       " 2.0752710042870604e-05,\n",
       " 3.173915683873929e-05,\n",
       " -1.2197350542919594e-06,\n",
       " 2.058710924757179e-05,\n",
       " 2.7680269340635277e-05,\n",
       " 1.4185608051775489e-05,\n",
       " 8.531259823030268e-07,\n",
       " -1.0934204510704149e-06,\n",
       " 1.034059664561937e-06,\n",
       " -8.908572795007785e-07,\n",
       " 6.966009209463664e-07,\n",
       " -4.5737061782347155e-07,\n",
       " 1.7340767044515815e-07,\n",
       " 1.5752340232211282e-07,\n",
       " -5.412163091023103e-07,\n",
       " 9.917471288645174e-07,\n",
       " -1.5447968735315953e-06,\n",
       " 2.3030499960441375e-06,\n",
       " -3.672672391985543e-06,\n",
       " 1.0625998584146146e-05,\n",
       " 7.633161089870555e-07,\n",
       " 9.577926903148182e-06,\n",
       " 3.305587961222045e-05,\n",
       " 2.9288801670190878e-05,\n",
       " 3.217161793145351e-05,\n",
       " 2.3107901142793708e-05,\n",
       " 2.4180599211831577e-05,\n",
       " 3.090802010774496e-06,\n",
       " 1.5491232261410914e-05,\n",
       " 6.7830246734956745e-06,\n",
       " 6.355117875500582e-06,\n",
       " 1.3011722330702469e-05,\n",
       " -2.019043449763558e-06,\n",
       " 1.1540472542037605e-06,\n",
       " 3.4249063673996716e-07,\n",
       " -1.8609453036333434e-05,\n",
       " -3.452948294579983e-05,\n",
       " -2.8025429855915718e-05,\n",
       " -3.2679618016118184e-05,\n",
       " -2.7565281925490126e-05,\n",
       " -2.768602143987664e-06,\n",
       " 1.2336437293924973e-06,\n",
       " -1.357803284918191e-06,\n",
       " 1.6678337487974204e-05,\n",
       " 1.372230144625064e-05,\n",
       " 3.2969124731607735e-05,\n",
       " 2.1130452296347357e-05,\n",
       " -3.4126496757380664e-06,\n",
       " 2.446252892696066e-06,\n",
       " -2.1179339455557056e-06,\n",
       " 1.9749131752178073e-06,\n",
       " -1.934130295921932e-06,\n",
       " 2.0655652406276204e-06,\n",
       " -3.421455403440632e-06,\n",
       " -2.7180647521163337e-05,\n",
       " -3.2601121347397566e-05,\n",
       " -2.8754162485711277e-05,\n",
       " -3.252746682846919e-05,\n",
       " -2.834196675394196e-05,\n",
       " -3.390687925275415e-05,\n",
       " -1.957819222297985e-05,\n",
       " 1.4471708027485874e-06,\n",
       " 1.1452700618974632e-06,\n",
       " 2.7787396902567707e-05,\n",
       " 1.2721972098006518e-06,\n",
       " 1.2490377230278682e-06,\n",
       " -9.114666681853123e-06,\n",
       " -3.3129465009551495e-05,\n",
       " 2.4558421500842087e-06,\n",
       " -2.0281559045542963e-05,\n",
       " -1.7696545455692103e-06,\n",
       " -6.9063203227415215e-06,\n",
       " -5.332924956746865e-06,\n",
       " 2.773508413156378e-06,\n",
       " -2.2522456220031017e-06,\n",
       " 1.2612662203537184e-06,\n",
       " -3.336117515573278e-05,\n",
       " -7.197340437414823e-06,\n",
       " -1.9239196262788028e-05,\n",
       " -2.050061993941199e-05,\n",
       " -7.843910680094268e-06,\n",
       " -5.505911303771427e-06,\n",
       " 2.7346859496901743e-06,\n",
       " -1.8529193539507105e-06,\n",
       " 1.3561797231886885e-06,\n",
       " -1.0244893928756937e-06,\n",
       " 7.930879064588225e-07,\n",
       " -6.398346386049525e-07,\n",
       " 5.613938469650748e-07,\n",
       " -5.697671099369472e-07,\n",
       " 7.031422910586116e-07,\n",
       " -1.0763866384877474e-06,\n",
       " 2.1699634089600295e-06,\n",
       " -2.0100860638194717e-05,\n",
       " -3.331602783873677e-05,\n",
       " -2.897521699196659e-05,\n",
       " -3.2822605135152116e-05,\n",
       " -6.023092282703146e-05,\n",
       " -4.277640618965961e-05,\n",
       " -2.6353567591286264e-05,\n",
       " -3.378087421879172e-05,\n",
       " -2.773793676169589e-05,\n",
       " -3.247755375923589e-05,\n",
       " 3.2146674584510038e-06,\n",
       " -2.254818355140742e-05,\n",
       " 8.61538228491554e-06,\n",
       " 2.4309154468937777e-05,\n",
       " -3.5580742405727506e-06,\n",
       " 3.335637302370742e-05,\n",
       " 9.387356840306893e-06,\n",
       " -1.969849336092011e-06,\n",
       " 1.1809502211690415e-06,\n",
       " -1.0294651247022557e-06,\n",
       " 1.0518454018892953e-06,\n",
       " -1.158601776296564e-06,\n",
       " 1.3623886161440169e-06,\n",
       " -1.8184234704676783e-06,\n",
       " 3.8110219975351356e-06,\n",
       " 1.4095502592681441e-05,\n",
       " 2.2854037524666637e-05,\n",
       " 3.1073297577677295e-05,\n",
       " 1.0067193215945736e-05,\n",
       " 3.3615144729992608e-06,\n",
       " 2.1572293917415664e-05,\n",
       " 9.22537856240524e-06,\n",
       " 1.6360161680495366e-05,\n",
       " 3.2936164643615484e-05,\n",
       " 2.828644574037753e-05,\n",
       " 3.326536534586921e-05,\n",
       " 2.721883538470138e-05,\n",
       " 3.562310666893609e-05,\n",
       " 1.6596311979810707e-05,\n",
       " 9.383074939250946e-06,\n",
       " 3.1255764042725787e-05,\n",
       " 9.737905202200636e-07,\n",
       " -2.5120738200712367e-07,\n",
       " 4.330665888119256e-07,\n",
       " -5.940562459727516e-07,\n",
       " 6.630282882724714e-07,\n",
       " -5.569230552282534e-07,\n",
       " -1.338431019348718e-07,\n",
       " 7.172995992732467e-06,\n",
       " 3.761937114177272e-05,\n",
       " 1.5815216102055274e-05,\n",
       " 1.9811122911050916e-05,\n",
       " 3.139506225124933e-05,\n",
       " 5.665636422236275e-07,\n",
       " 3.727543003151368e-07,\n",
       " -3.6795051983062876e-07,\n",
       " 3.425850820804044e-07,\n",
       " -3.475102801075991e-07,\n",
       " 3.8648911981908896e-07,\n",
       " -4.686898193995148e-07,\n",
       " 6.276055728449137e-07,\n",
       " -9.727001497594756e-07,\n",
       " 1.976159182959236e-06,\n",
       " -9.561805200064555e-06,\n",
       " -3.3852484193630517e-05,\n",
       " -2.821345151460264e-05,\n",
       " -3.2914798794081435e-05,\n",
       " -2.792911254800856e-05,\n",
       " -3.442418164922856e-05,\n",
       " -1.893259832286276e-05,\n",
       " 7.686249432481418e-07,\n",
       " 6.43187661353295e-07,\n",
       " -1.5897131788733532e-06,\n",
       " 3.045703579118708e-06,\n",
       " -1.1156502296216786e-05,\n",
       " -3.0551069357898086e-05,\n",
       " -1.2513080491771689e-06,\n",
       " 2.6557339083410625e-07,\n",
       " -2.26537437697516e-07,\n",
       " 1.5348656745572953e-07,\n",
       " 7.233441579046485e-08,\n",
       " -6.083898256292741e-07,\n",
       " 2.0404006590979407e-06,\n",
       " -1.0764897524495609e-05,\n",
       " -1.470591359975515e-05,\n",
       " 6.17152272752719e-06,\n",
       " -6.239595677470788e-06,\n",
       " -2.4628963728901e-05,\n",
       " -3.5562603443395346e-05,\n",
       " -2.3230877559399232e-05,\n",
       " -2.6054827685584314e-05,\n",
       " -2.148799285350833e-05,\n",
       " 3.30125317304919e-06,\n",
       " -1.4556270798493642e-05,\n",
       " -8.891434845281765e-06,\n",
       " 1.8810073925124016e-06,\n",
       " -3.284890772192739e-05,\n",
       " -1.9440285541350022e-05,\n",
       " 1.3712775626117946e-06,\n",
       " -2.5923236535163596e-07,\n",
       " -1.403825820034399e-07,\n",
       " 3.101733057064848e-07,\n",
       " 9.828377187659498e-06,\n",
       " 3.542345154983195e-07,\n",
       " -2.1627558055570262e-07,\n",
       " -1.2264803217476583e-07,\n",
       " 1.0992491752404021e-06,\n",
       " -8.532570973329712e-06,\n",
       " -2.5440580429858528e-05,\n",
       " -8.9524473878555e-06,\n",
       " 1.8181647192250239e-06,\n",
       " 1.0020567970059346e-05,\n",
       " 3.187971014995128e-05,\n",
       " 1.9889890609192662e-05,\n",
       " -1.044158125296235e-06,\n",
       " -2.6488301045901608e-06,\n",
       " -9.801094165595714e-06,\n",
       " 5.215218152443413e-06,\n",
       " 1.9532266378519125e-05,\n",
       " -5.234746822679881e-06,\n",
       " 1.3838035556545947e-05,\n",
       " 1.066773802449461e-05,\n",
       " 5.520611921383534e-06,\n",
       " 3.723255576915108e-05,\n",
       " 7.869756700529251e-06,\n",
       " -9.597370080882683e-07,\n",
       " 3.535909911533963e-07,\n",
       " -2.6797974328474083e-07,\n",
       " 2.928418609826622e-07,\n",
       " -3.4571138485262054e-07,\n",
       " 4.0440599491375906e-07,\n",
       " -4.6310589141285163e-07,\n",
       " 5.215295004745713e-07,\n",
       " -5.80760854518303e-07,\n",
       " 6.358612267831631e-07,\n",
       " -6.246580710467242e-07,\n",
       " -3.9881811630948505e-07,\n",
       " -3.1230236345436424e-05,\n",
       " -1.0700474376790226e-05,\n",
       " 2.816321966747637e-06,\n",
       " -1.6799220929897274e-06,\n",
       " 9.747177500685211e-07,\n",
       " 4.230210379319033e-06,\n",
       " 2.554927414166741e-05,\n",
       " -1.7158323544208542e-06,\n",
       " 2.2742906367057003e-05,\n",
       " 2.245600444439333e-05,\n",
       " -2.944048901554197e-06,\n",
       " 7.584379773106775e-07,\n",
       " 1.3808236190016032e-06,\n",
       " -2.0665496776928194e-05,\n",
       " -2.5020292014232837e-05,\n",
       " 6.158091309771407e-06,\n",
       " -5.44937120139366e-06,\n",
       " 2.1307972929207608e-05,\n",
       " 1.7481447684986051e-06,\n",
       " 2.053978732874384e-06,\n",
       " 2.6816373065230437e-05,\n",
       " 2.196999275838607e-06,\n",
       " 3.930330763068923e-07,\n",
       " -1.8472986994311213e-05,\n",
       " -2.4749921067268588e-05,\n",
       " -2.7581188987824135e-05,\n",
       " -2.8458232918637805e-05,\n",
       " -1.1392010492272675e-05,\n",
       " -1.184954362543067e-05,\n",
       " -2.9578321118606254e-05,\n",
       " -1.2429390153556596e-05,\n",
       " 1.2220265261930763e-06,\n",
       " -1.219052023770928e-06,\n",
       " 1.2713948081000126e-06,\n",
       " -1.333690761384787e-06,\n",
       " 1.4287830936154933e-06,\n",
       " -1.6202857295866124e-06,\n",
       " 2.112139327437035e-06,\n",
       " -4.3488166738825385e-06,\n",
       " -1.9977624106104486e-05,\n",
       " -2.7083138775196858e-05,\n",
       " -3.1838611903367564e-05,\n",
       " -2.990083521581255e-05,\n",
       " -3.103948256466538e-05,\n",
       " -3.0421308110817336e-05,\n",
       " -2.947053508250974e-05,\n",
       " -6.875030180708563e-07,\n",
       " -3.189144763382501e-06,\n",
       " -8.828208592603914e-06,\n",
       " -4.233678737364244e-06,\n",
       " -4.017080209450796e-05,\n",
       " -1.2780466022377368e-05,\n",
       " -2.4342589313164353e-05,\n",
       " -1.8994289348484017e-05,\n",
       " -9.188494004774839e-06,\n",
       " -1.4491554793494288e-05,\n",
       " 4.980573521606857e-06,\n",
       " -3.184774186593131e-06,\n",
       " 2.5440517674724106e-06,\n",
       " -2.529422090447042e-06,\n",
       " 3.4836684790207073e-06,\n",
       " -2.170034531445708e-05,\n",
       " -1.649996374908369e-05,\n",
       " -1.4818835552432574e-05,\n",
       " -5.184938345337287e-06,\n",
       " -1.5442556104972027e-05,\n",
       " -2.8269474569242448e-05,\n",
       " -5.393004812503932e-06,\n",
       " -1.8738803191808984e-05,\n",
       " 2.4565201783843804e-06,\n",
       " -2.0492784642556217e-06,\n",
       " 4.056755642523058e-06,\n",
       " 8.93916603672551e-06,\n",
       " -2.866191834982601e-06,\n",
       " 2.1712660327466438e-06,\n",
       " -1.9831616100418614e-06,\n",
       " 1.9429569420026382e-06,\n",
       " -2.0331253836047836e-06,\n",
       " 3.1950537504599197e-06,\n",
       " 2.8136671971878968e-05,\n",
       " 2.5506940801278688e-05,\n",
       " 2.3008724383544177e-05,\n",
       " 3.592396751628257e-05,\n",
       " 2.5388279027538374e-05,\n",
       " 3.678442590171471e-05,\n",
       " 1.655243795539718e-05,\n",
       " 2.836275371009833e-06,\n",
       " 2.6549192625680007e-05,\n",
       " 2.3638620405108668e-05,\n",
       " 2.694115391932428e-05,\n",
       " 3.543135244399309e-05,\n",
       " 1.785801759979222e-05,\n",
       " 1.5496086689381627e-06,\n",
       " 2.6866689950111322e-05,\n",
       " 1.1963344149990007e-05,\n",
       " 1.729321047605481e-05,\n",
       " 3.6958546843379736e-05,\n",
       " 7.56889266995131e-06,\n",
       " 1.0818480404850561e-05,\n",
       " 3.0328887078212574e-05,\n",
       " 1.1666371392493602e-05,\n",
       " -3.6653050301538315e-06,\n",
       " 2.372918970650062e-06,\n",
       " -1.7570552017787122e-06,\n",
       " 1.3268207794681075e-06,\n",
       " -9.624027370591648e-07,\n",
       " 6.190213071022299e-07,\n",
       " -2.7394969492888777e-07,\n",
       " -8.295457121221261e-08,\n",
       " 4.0614810359329567e-07,\n",
       " 2.245038643877706e-07,\n",
       " 2.1734826077590697e-05,\n",
       " 9.103117008635309e-06,\n",
       " 1.5498864058827166e-06,\n",
       " 9.757593943504617e-06,\n",
       " 7.387828645732952e-06,\n",
       " 1.5286325378838228e-06,\n",
       " -8.725516522645194e-07,\n",
       " 1.0619294698699377e-05,\n",
       " -4.3301657370875546e-08,\n",
       " -2.908406315782486e-07,\n",
       " 6.513313905998075e-07,\n",
       " -1.1508182069519535e-06,\n",
       " 2.2395242922357284e-06,\n",
       " -1.9927929315599613e-05,\n",
       " -3.4433443943271413e-05,\n",
       " -1.016959868138656e-05,\n",
       " 3.0831515687168576e-06,\n",
       " -2.495759190423996e-06,\n",
       " 2.631086999826948e-06,\n",
       " -3.272892399763805e-06,\n",
       " 5.86712985750637e-06,\n",
       " 1.686550058366265e-05,\n",
       " -1.6659571144828078e-07,\n",
       " -1.1115801498817746e-05,\n",
       " 1.4956815448385896e-06,\n",
       " -2.029645429502125e-06,\n",
       " -7.372590062004747e-06,\n",
       " -5.468099971039919e-06,\n",
       " -7.124696367100114e-06,\n",
       " 7.776593520247843e-07,\n",
       " 9.015203517037662e-08,\n",
       " -3.56454904704151e-07,\n",
       " 3.792544589487079e-07,\n",
       " -2.1198532351718313e-07,\n",
       " -2.2511855490847665e-07,\n",
       " 1.3930171007814351e-06,\n",
       " -1.9392087779124267e-05,\n",
       " -3.3981003070948645e-05,\n",
       " -2.833566213666927e-05,\n",
       " -3.271080640843138e-05,\n",
       " -2.665445026650559e-05,\n",
       " -2.1081536033307202e-05,\n",
       " -3.524636122165248e-05,\n",
       " -8.611381417722441e-06,\n",
       " 8.857151101437921e-07,\n",
       " 4.7216582288456266e-07,\n",
       " -2.393795057287207e-06,\n",
       " -2.784761272778269e-05,\n",
       " -3.221416045562364e-05,\n",
       " -2.8823471438954584e-05,\n",
       " -3.325093712192029e-05,\n",
       " -2.049973772955127e-05,\n",
       " 1.9759295355470385e-06,\n",
       " -3.330664912937209e-05,\n",
       " -1.7483132978668436e-05,\n",
       " -1.969631739484612e-05,\n",
       " -1.4557250324287452e-05,\n",
       " 5.053729182691313e-06,\n",
       " -3.0050152872718172e-06,\n",
       " 1.770133735590207e-06,\n",
       " -2.9448784744090517e-07,\n",
       " -7.373736480076332e-06,\n",
       " -3.6851710319751874e-05,\n",
       " -1.718376915960107e-05,\n",
       " -1.757069185259752e-05,\n",
       " -3.6330457078292966e-05,\n",
       " -1.8356478904024698e-05,\n",
       " 7.937964596749225e-07,\n",
       " 1.3883348515264515e-07,\n",
       " -4.6863505076544243e-07,\n",
       " 6.266750460781623e-07,\n",
       " -7.136213753256015e-07,\n",
       " 7.724153761046182e-07,\n",
       " -8.40359518861078e-07,\n",
       " 9.830508815866779e-07,\n",
       " -1.4037129858479602e-06,\n",
       " 3.5475090953696053e-06,\n",
       " 1.0709193702496123e-05,\n",
       " 2.5974377422244288e-05,\n",
       " 3.31565533997491e-05,\n",
       " 2.830997073033359e-05,\n",
       " 3.301817923784256e-05,\n",
       " 2.7748454158427194e-05,\n",
       " 3.461515007074922e-05,\n",
       " 8.600902219768614e-06,\n",
       " -7.74915577039792e-07,\n",
       " 9.712007340567652e-06,\n",
       " 2.110812374667148e-06,\n",
       " 2.9076554710627533e-05,\n",
       " 1.3384531484916806e-05,\n",
       " -6.650082013948122e-06,\n",
       " 1.3278217920742463e-05,\n",
       " 3.0353181500686333e-05,\n",
       " 3.176533573423512e-05,\n",
       " 2.9105713110766374e-05,\n",
       " 2.2122985683381557e-05,\n",
       " 2.8555501558003016e-05,\n",
       " 3.344615834066644e-05,\n",
       " 2.158567622245755e-05,\n",
       " 2.6757588784676045e-05,\n",
       " 3.219542486476712e-05,\n",
       " 2.915747245424427e-05,\n",
       " 3.290967651992105e-05,\n",
       " 1.0514910172787495e-05,\n",
       " -2.8731651582347695e-06,\n",
       " 1.8780879145197105e-06,\n",
       " -1.5927203094179276e-06,\n",
       " 1.5635032468708232e-06,\n",
       " -1.7235640825674636e-06,\n",
       " 2.164271108995308e-06,\n",
       " -3.3990825158980442e-06,\n",
       " 1.1614726645348128e-05,\n",
       " 1.6178137229871936e-05,\n",
       " 1.5622536011505872e-05,\n",
       " -8.458536626676505e-07,\n",
       " 1.4360849718286772e-06,\n",
       " -8.85418376128655e-06,\n",
       " -3.38010213454254e-05,\n",
       " -6.3042530200618785e-06,\n",
       " -2.443801349727437e-05,\n",
       " -1.0015930456575006e-05,\n",
       " -5.3257735999068245e-06,\n",
       " -5.5748764680174645e-06,\n",
       " 2.0907511952827917e-06,\n",
       " -6.788829409742902e-07,\n",
       " -4.862321247856016e-07,\n",
       " 2.1636167275573825e-06,\n",
       " -1.0378186743764672e-05,\n",
       " -4.257410182617605e-05,\n",
       " -3.0472305297735147e-05,\n",
       " -2.9604258088511415e-05,\n",
       " -3.320185714983381e-05,\n",
       " -1.9783205061685294e-05,\n",
       " 9.339495932181308e-07,\n",
       " 6.2777498897048645e-06,\n",
       " 6.500740710180253e-06,\n",
       " -5.171050361241214e-06,\n",
       " 1.2882831470051315e-05,\n",
       " 2.7907492039958015e-05,\n",
       " 2.2348571292241104e-05,\n",
       " 2.6073876142618246e-05,\n",
       " 2.31536560022505e-05,\n",
       " 3.609908890211955e-05,\n",
       " 1.8366279618931003e-05,\n",
       " -1.023088543661288e-06,\n",
       " 6.95846381404408e-07,\n",
       " -1.591161526448559e-05,\n",
       " -2.4036160539253615e-05,\n",
       " 9.864113508228911e-07,\n",
       " 1.0059458873001859e-05,\n",
       " -4.006211383966729e-06,\n",
       " 5.472962129715597e-06,\n",
       " 7.654491128050722e-06,\n",
       " -1.6441628076790948e-06,\n",
       " 1.0425162599858595e-06,\n",
       " -1.0602842621665332e-06,\n",
       " 1.5341630614784663e-06,\n",
       " -3.8029340885259444e-06,\n",
       " -2.0564109945553355e-05,\n",
       " -2.533773658797145e-05,\n",
       " -2.5975721200666158e-06,\n",
       " 9.879314347926993e-06,\n",
       " 7.1516178650199436e-06,\n",
       " 5.243273335509002e-06,\n",
       " -2.5209390059899306e-06,\n",
       " 1.7247626828975626e-06,\n",
       " -1.2820323718187865e-06,\n",
       " 9.702247325549251e-07,\n",
       " -7.616761763529212e-07,\n",
       " 8.776993922765541e-07,\n",
       " -5.724853508581873e-06,\n",
       " -1.4194978575687855e-05,\n",
       " 1.8985022052220302e-06,\n",
       " 8.370994692086242e-06,\n",
       " -9.741178246258642e-07,\n",
       " -1.1683756383717991e-05,\n",
       " 2.017322367464658e-05,\n",
       " 3.2618598197586834e-05,\n",
       " 3.037913302250672e-05,\n",
       " 2.9497352443286218e-05,\n",
       " 3.3596475986996666e-05,\n",
       " 1.8866276150220074e-05,\n",
       " 1.938858531502774e-06,\n",
       " 9.333063644589856e-06,\n",
       " -2.3370084818452597e-06,\n",
       " 9.958383770936052e-07,\n",
       " -2.8820818442909513e-07,\n",
       " -2.4341534299310297e-07,\n",
       " 8.520922278876242e-07,\n",
       " -2.7721434889826924e-06,\n",
       " -2.6046811399282888e-05,\n",
       " -3.682758688228205e-06,\n",
       " 3.251315092711593e-06,\n",
       " -2.097381184285041e-05,\n",
       " -3.255865885876119e-05,\n",
       " -2.8701286282739602e-05,\n",
       " -5.217181637817703e-07,\n",
       " -1.7872544049168937e-05,\n",
       " -3.816695880232146e-06,\n",
       " -1.631641498534009e-05,\n",
       " -3.757854938157834e-05,\n",
       " -7.013407412159722e-06,\n",
       " -1.316520751970529e-06,\n",
       " -2.926370689237956e-05,\n",
       " -2.362204759265296e-05,\n",
       " 7.02882653058623e-06,\n",
       " -1.4704439308843575e-05,\n",
       " -1.0974732504109852e-05,\n",
       " 1.1932739880649024e-06,\n",
       " -2.092626345984172e-05,\n",
       " -2.3141239580581896e-05,\n",
       " -2.473890344845131e-05,\n",
       " -3.642474621301517e-05,\n",
       " -3.839288547169417e-05,\n",
       " -2.6722560505731963e-05,\n",
       " -2.046288500423543e-05,\n",
       " -3.607769394875504e-05,\n",
       " -1.7410991858923808e-05,\n",
       " -6.31769944448024e-06,\n",
       " -5.907403192395577e-06,\n",
       " 4.3329632717359345e-06,\n",
       " -1.1578681551327463e-05,\n",
       " -3.146098242723383e-05,\n",
       " -3.194618329871446e-05,\n",
       " -1.0789836778712925e-05,\n",
       " 2.6451164103491465e-06,\n",
       " -2.1275832295941655e-06,\n",
       " -3.0456887543550692e-05,\n",
       " -1.0514601854083594e-05,\n",
       " 1.169622350971622e-06,\n",
       " 6.821663191658445e-06,\n",
       " 4.783491476700874e-06,\n",
       " -1.088725639419863e-06,\n",
       " -2.4829535050230334e-06,\n",
       " -1.9719389456440695e-05,\n",
       " 2.691045665415004e-06,\n",
       " -1.3977113439977984e-06,\n",
       " 7.169453510869062e-07,\n",
       " -3.2302841646014713e-07,\n",
       " 1.0647539738783962e-06,\n",
       " 3.0750550649827346e-05,\n",
       " 2.127731750078965e-05,\n",
       " -3.2087243653222686e-06,\n",
       " 2.381920467087184e-06,\n",
       " -2.99207658827072e-06,\n",
       " 1.0461722922627814e-05,\n",
       " 3.290929817012511e-05,\n",
       " 2.93297489406541e-05,\n",
       " 3.1476574804401025e-05,\n",
       " 2.9942279070382938e-05,\n",
       " 3.1110212148632854e-05,\n",
       " 3.0204380891518667e-05,\n",
       " 3.090660902671516e-05,\n",
       " 3.0361872632056475e-05,\n",
       " 3.080158057855442e-05,\n",
       " 3.038611976080574e-05,\n",
       " 3.093665873166174e-05,\n",
       " 2.9827238904545084e-05,\n",
       " 3.363928772159852e-05,\n",
       " 4.0621322114020586e-05,\n",
       " 2.5982410079450347e-05,\n",
       " 4.063060987391509e-05,\n",
       " 4.3812597141368315e-05,\n",
       " 2.9875054678996094e-05,\n",
       " 3.0947419872973114e-05,\n",
       " 3.0147095458232798e-05,\n",
       " 3.251121597713791e-05,\n",
       " 4.892608194495551e-05,\n",
       " 6.206145917531103e-05,\n",
       " 6.025160473654978e-05,\n",
       " 6.240366928977892e-05,\n",
       " 6.060916348360479e-05,\n",
       " 9.400967246619985e-05,\n",
       " 7.961493247421458e-05,\n",
       " 6.263794784899801e-05,\n",
       " 4.9912629037862644e-05,\n",
       " 3.260507219238207e-05,\n",
       " 4.962619277648628e-05,\n",
       " 2.936241617135238e-05,\n",
       " 2.9342130801524036e-05,\n",
       " 3.925858982256614e-05,\n",
       " 3.322814518469386e-05,\n",
       " 3.715170532814227e-05,\n",
       " 3.5841581848217174e-05,\n",
       " 2.833599501173012e-05,\n",
       " 3.198346166755073e-05,\n",
       " 2.9610822821268812e-05,\n",
       " 3.152938006678596e-05,\n",
       " 2.8438123990781605e-05,\n",
       " 1.2155464901297819e-05,\n",
       " 1.1029583220079076e-05,\n",
       " 2.9680668376386166e-05,\n",
       " 2.9935543352621607e-05,\n",
       " 3.1884170311968774e-05,\n",
       " 2.7513915483723395e-05,\n",
       " 3.705710469148471e-06,\n",
       " -3.588825165934395e-06,\n",
       " 2.1614487195620313e-05,\n",
       " 3.0429613616433926e-05,\n",
       " 1.2146143717473024e-06,\n",
       " 3.53227250116106e-07,\n",
       " -1.702631743683014e-05,\n",
       " -5.4599400755250826e-05,\n",
       " -5.98766200710088e-05,\n",
       " -3.1884545023785904e-05,\n",
       " -4.7918878408381715e-05,\n",
       " -6.774238136131316e-05,\n",
       " -3.8878417399246246e-05,\n",
       " -6.129592657089233e-05,\n",
       " -4.082686791662127e-05,\n",
       " -2.982064506795723e-05,\n",
       " -6.0916678194189444e-05,\n",
       " -6.0312202549539506e-05,\n",
       " -6.138539174571633e-05,\n",
       " -2.8908381864312105e-05,\n",
       " -5.262506601866335e-05,\n",
       " -5.539249104913324e-05,\n",
       " -5.564544699154794e-05,\n",
       " -6.363990542013198e-05,\n",
       " -5.978812259854749e-05,\n",
       " -6.1898521380499e-05,\n",
       " -6.22465813648887e-05,\n",
       " -9.042984311236069e-05,\n",
       " -9.23675179365091e-05,\n",
       " -8.516164234606549e-05,\n",
       " -3.6155608540866524e-05,\n",
       " -4.9640355427982286e-05,\n",
       " -6.425270839827135e-05,\n",
       " -5.960633643553592e-05,\n",
       " -6.197117909323424e-05,\n",
       " -6.161595229059458e-05,\n",
       " -5.327102553565055e-05,\n",
       " -2.506997225282248e-05,\n",
       " -4.13289999414701e-05,\n",
       " -3.288940206402913e-05,\n",
       " -3.0790666642133147e-05,\n",
       " -2.957651850010734e-05,\n",
       " -3.254295006627217e-05,\n",
       " -2.5968696718337014e-05,\n",
       " -1.1557383004401345e-05,\n",
       " -1.2247963923073257e-06,\n",
       " -9.086801583180204e-06,\n",
       " -3.31497831211891e-05,\n",
       " -3.038860813830979e-05,\n",
       " -2.386600863246713e-05,\n",
       " -2.5032655685208738e-05,\n",
       " -3.343297794344835e-05,\n",
       " -2.8413731342880055e-05,\n",
       " -3.365527663845569e-05,\n",
       " -5.891085311304778e-05,\n",
       " -5.559193232329562e-05,\n",
       " -1.533574868517462e-05,\n",
       " -7.62357740313746e-06,\n",
       " 5.685712494596373e-06,\n",
       " 1.8512160977479653e-06,\n",
       " -1.0958509477632106e-07,\n",
       " 3.1086907256394625e-05,\n",
       " 2.6241095838486217e-05,\n",
       " 2.2538259145221673e-05,\n",
       " 3.2165309676202014e-05,\n",
       " 3.01440195471514e-05,\n",
       " 2.0225219486746937e-05,\n",
       " 3.1352825317298993e-05,\n",
       " 2.908227361331228e-05,\n",
       " 3.3592110412428156e-05,\n",
       " 1.943926326930523e-05,\n",
       " -8.146269010467222e-07,\n",
       " -1.6654772707624943e-06,\n",
       " 1.0211550034000538e-05,\n",
       " 2.1017136532464065e-05,\n",
       " 8.092350753940991e-07,\n",
       " -5.973242878098972e-08,\n",
       " 2.879860687698965e-07,\n",
       " -5.532979230338242e-07,\n",
       " 8.119032486320066e-07,\n",
       " -1.0914477570622694e-06,\n",
       " 1.466607045585988e-06,\n",
       " -2.17253113987681e-06,\n",
       " 4.781192274094792e-06,\n",
       " 1.7848391507868655e-05,\n",
       " 1.133919766971303e-07,\n",
       " 2.9558304959209636e-05,\n",
       " 3.054590706597082e-05,\n",
       " 3.0860217520967126e-05,\n",
       " 2.8873791961814277e-05,\n",
       " 3.0856729154038476e-06,\n",
       " 2.7890233468497172e-05,\n",
       " 5.03173282595526e-07,\n",
       " 1.2540063835331239e-05,\n",
       " -6.352678155963076e-06,\n",
       " 1.6231595054705394e-06,\n",
       " 3.515521893859841e-05,\n",
       " 2.8078075047233142e-05,\n",
       " 4.286126568331383e-05,\n",
       " 1.3721486538997851e-05,\n",
       " 6.274180577747757e-06,\n",
       " -7.129330015231972e-07,\n",
       " -7.991154404862755e-08,\n",
       " 5.67344272894843e-07,\n",
       " -1.1327867923682788e-06,\n",
       " 2.3132467958930647e-06,\n",
       " -2.024267269007396e-05,\n",
       " -3.3255892049055547e-05,\n",
       " -2.892396332754288e-05,\n",
       " -3.2111369364429265e-05,\n",
       " -2.8778253181371838e-05,\n",
       " -3.366770033608191e-05,\n",
       " -1.902856820379384e-05,\n",
       " -1.6350402802345343e-05,\n",
       " -3.712019315571524e-05,\n",
       " -8.588810487708542e-06,\n",
       " -3.140491753583774e-05,\n",
       " -4.067610279889777e-05,\n",
       " -2.6220655854558572e-05,\n",
       " -4.146433639107272e-05,\n",
       " -6.416848191292956e-05,\n",
       " -5.1899369282182306e-05,\n",
       " -2.6126348529942334e-05,\n",
       " -3.5950761230196804e-05,\n",
       " -6.01211104367394e-06,\n",
       " -1.0638606909196824e-05,\n",
       " -1.3057177966402378e-05,\n",
       " -1.1759239896491636e-05,\n",
       " -1.6781283193267882e-05,\n",
       " -3.0670431442558765e-05,\n",
       " -2.3230022634379566e-05,\n",
       " 6.103020950831706e-06,\n",
       " -2.159620271413587e-05,\n",
       " -1.0030158819063217e-06,\n",
       " -8.418218385486398e-06,\n",
       " -3.56460441253148e-05,\n",
       " -8.580394933233038e-06,\n",
       " -2.433557426684274e-07,\n",
       " -2.9209317290224135e-05,\n",
       " -3.156654565827921e-05,\n",
       " -1.2962108485226054e-05,\n",
       " 1.3380802556639537e-05,\n",
       " 1.537419666419737e-05,\n",
       " 1.7754853615770116e-05,\n",
       " 2.1640000340994447e-05,\n",
       " -2.255029721709434e-05,\n",
       " -2.727033461269457e-07,\n",
       " -3.7000304473622236e-06,\n",
       " 1.3264561857795343e-05,\n",
       " 2.1642301362589933e-05,\n",
       " -8.343895956386405e-07,\n",
       " 2.9564023861894384e-05,\n",
       " 3.120637484244071e-05,\n",
       " 2.9353686841204762e-05,\n",
       " 3.310887041152455e-05,\n",
       " 2.035448414972052e-05,\n",
       " -2.5818364974838914e-06,\n",
       " 2.1157588889764156e-06,\n",
       " ...]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_data[0]['array']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmetation(RIR applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_raw,_ = librosa.load('./outputs/rir_data.wav',sr)\n",
    "\n",
    "def rir_applied(batch):\n",
    "    rir = torch.from_numpy( rir_raw[int(sr * 2.44) : int(sr * 2.7)].reshape(1,-1) )\n",
    "    rir = rir / torch.norm(rir, p=2)\n",
    "    rir = torch.flip(rir,[1])\n",
    "\n",
    "    speech = torch.from_numpy(np.array(batch['array'],dtype=np.float32).reshape(1,-1))\n",
    "\n",
    "    speech_ = torch.nn.functional.pad(speech, (rir.shape[1] - 1, 0))\n",
    "    # print(speech.dtype)\n",
    "    # print(speech_.dtype)\n",
    "    # print(rir.dtype)\n",
    "    augmented = torch.nn.functional.conv1d(speech_[None, ...], rir[None, ...])[0]\n",
    "    batch['array'] = augmented.reshape(-1)\n",
    "    return batch\n",
    "\n",
    "def fast_stretching(batch):\n",
    "    array = np.array(batch['array'],dtype=np.float32)\n",
    "    batch['array'] = librosa.effects.time_stretch(array,0.8)\n",
    "    return batch\n",
    "\n",
    "def slow_stretching(batch):\n",
    "    array = np.array(batch['array'],dtype=np.float32)\n",
    "    batch['array'] = librosa.effects.time_stretch(array,1.5)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-65bbdea21c07bf7c.arrow\n"
     ]
    }
   ],
   "source": [
    "rir_applied_audio_data = audio_data.map(rir_applied)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-17315fa06a7e7424.arrow\n"
     ]
    }
   ],
   "source": [
    "fast_stretching_data = audio_data.map(fast_stretching)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-f39a22ddda49e783.arrow\n"
     ]
    }
   ],
   "source": [
    "slow_stretching_data = audio_data.map(slow_stretching)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZiv4zqyt2cY"
   },
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "AscOxzgUsb50"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(batch):\n",
    "\n",
    "    # batched output is \"un-batched\"\n",
    "    batch[\"input_values\"] = processor(batch[\"array\"], sampling_rate=16000).input_values[0]\n",
    "    \n",
    "    with processor.as_target_processor():\n",
    "        batch[\"labels\"] = processor(batch[\"text\"]).input_ids\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-7937b1f431298145.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-755e215030b240ce.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-8efbe5848551afc6.arrow\n",
      "Loading cached processed dataset at C:\\Users\\AI_server\\.cache\\huggingface\\datasets\\csv\\default-0f216d6397fe291f\\0.0.0\\433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519\\cache-c785becfa8ad27a7.arrow\n"
     ]
    }
   ],
   "source": [
    "ds_list = [audio_data, rir_applied_audio_data, fast_stretching_data, slow_stretching_data]\n",
    "prepare_ds_list = []\n",
    "for ds in ds_list:\n",
    "    prepare_ds_list.append(ds.map(\n",
    "        prepare_dataset,\n",
    "        remove_columns=ds.column_names,\n",
    "        # num_proc=2\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_data = torch.utils.data.ConcatDataset(prepare_ds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StCtCQxDtuY3"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUTqiRY-tpXZ"
   },
   "source": [
    "## Set-up Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "nTlewiOzsyqR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Dict, List, Optional, Union\n",
    "\n",
    "@dataclass\n",
    "class DataCollatorCTCWithPadding:\n",
    "    \"\"\"\n",
    "    Data collator that will dynamically pad the inputs received.\n",
    "    Args:\n",
    "        processor (:class:`~transformers.Wav2Vec2Processor`)\n",
    "            The processor used for proccessing the data.\n",
    "        padding (:obj:`bool`, :obj:`str` or :class:`~transformers.tokenization_utils_base.PaddingStrategy`, `optional`, defaults to :obj:`True`):\n",
    "            Select a strategy to pad the returned sequences (according to the model's padding side and padding index)\n",
    "            among:\n",
    "            * :obj:`True` or :obj:`'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
    "              sequence if provided).\n",
    "            * :obj:`'max_length'`: Pad to a maximum length specified with the argument :obj:`max_length` or to the\n",
    "              maximum acceptable input length for the model if that argument is not provided.\n",
    "            * :obj:`False` or :obj:`'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of\n",
    "              different lengths).\n",
    "        max_length (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``input_values`` of the returned list and optionally padding length (see above).\n",
    "        max_length_labels (:obj:`int`, `optional`):\n",
    "            Maximum length of the ``labels`` returned list and optionally padding length (see above).\n",
    "        pad_to_multiple_of (:obj:`int`, `optional`):\n",
    "            If set will pad the sequence to a multiple of the provided value.\n",
    "            This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability >=\n",
    "            7.5 (Volta).\n",
    "    \"\"\"\n",
    "\n",
    "    processor: Wav2Vec2Processor\n",
    "    padding: Union[bool, str] = True\n",
    "    max_length: Optional[int] = None\n",
    "    max_length_labels: Optional[int] = None\n",
    "    pad_to_multiple_of: Optional[int] = None\n",
    "    pad_to_multiple_of_labels: Optional[int] = None\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Union[List[int], torch.cuda.HalfTensor]]]) -> Dict[str, torch.cuda.HalfTensor]:\n",
    "        # split inputs and labels since they have to be of different lenghts and need\n",
    "        # different padding methods\n",
    "        input_features = [{\"input_values\": feature[\"input_values\"]} for feature in features]\n",
    "        label_features = [{\"input_ids\": feature[\"labels\"]} for feature in features]\n",
    "\n",
    "        batch = self.processor.pad(\n",
    "            input_features,\n",
    "            padding=self.padding,\n",
    "            max_length=self.max_length,\n",
    "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        with self.processor.as_target_processor():\n",
    "            labels_batch = self.processor.pad(\n",
    "                label_features,\n",
    "                padding=self.padding,\n",
    "                max_length=self.max_length_labels,\n",
    "                pad_to_multiple_of=self.pad_to_multiple_of_labels,\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "\n",
    "        # replace padding with -100 to ignore loss correctly\n",
    "        labels = labels_batch[\"input_ids\"].masked_fill(labels_batch.attention_mask.ne(1), -100)\n",
    "\n",
    "        batch[\"labels\"] = labels\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "WmfIPs18tGQb"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorCTCWithPadding(processor=processor, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "vJjfNy9-tJM6"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric, Audio\n",
    "\n",
    "wer_metric = load_metric(\"wer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "03mNNUfNthSZ"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    pred_logits = pred.predictions\n",
    "    pred_ids = np.argmax(pred_logits, axis=-1)\n",
    "\n",
    "    pred.label_ids[pred.label_ids == -100] = processor.tokenizer.pad_token_id\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids)\n",
    "    # we do not want to group tokens when computing the metrics\n",
    "    label_str = processor.batch_decode(pred.label_ids, group_tokens=False)\n",
    "\n",
    "    wer = wer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"wer\": wer}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vgRoeQHvTqk"
   },
   "source": [
    "## Import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "Iyv4qaclue6n"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/wav2vec2-large-xlsr-53/resolve/main/config.json from cache at C:\\Users\\AI_server/.cache\\huggingface\\transformers\\8508c73cd595eb416a1d517b90762416c0bc6cfbef529578079aeae4d8c14336.7581ed2ee0c677f1e933180df51bd1a668c4a2b6d5fd1297d32069373dac097c\n",
      "Model config Wav2Vec2Config {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"adapter_kernel_size\": 3,\n",
      "  \"adapter_stride\": 2,\n",
      "  \"add_adapter\": false,\n",
      "  \"apply_spec_augment\": true,\n",
      "  \"architectures\": [\n",
      "    \"Wav2Vec2ForPreTraining\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classifier_proj_size\": 256,\n",
      "  \"codevector_dim\": 768,\n",
      "  \"contrastive_logits_temperature\": 0.1,\n",
      "  \"conv_bias\": true,\n",
      "  \"conv_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512\n",
      "  ],\n",
      "  \"conv_kernel\": [\n",
      "    10,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    3,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"conv_stride\": [\n",
      "    5,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"ctc_loss_reduction\": \"mean\",\n",
      "  \"ctc_zero_infinity\": false,\n",
      "  \"diversity_loss_weight\": 0.1,\n",
      "  \"do_stable_layer_norm\": true,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"feat_extract_activation\": \"gelu\",\n",
      "  \"feat_extract_dropout\": 0.0,\n",
      "  \"feat_extract_norm\": \"layer\",\n",
      "  \"feat_proj_dropout\": 0.0,\n",
      "  \"feat_quantizer_dropout\": 0.0,\n",
      "  \"final_dropout\": 0.0,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"layerdrop\": 0.1,\n",
      "  \"mask_channel_length\": 10,\n",
      "  \"mask_channel_min_space\": 1,\n",
      "  \"mask_channel_other\": 0.0,\n",
      "  \"mask_channel_prob\": 0.0,\n",
      "  \"mask_channel_selection\": \"static\",\n",
      "  \"mask_feature_length\": 10,\n",
      "  \"mask_feature_min_masks\": 0,\n",
      "  \"mask_feature_prob\": 0.0,\n",
      "  \"mask_time_length\": 10,\n",
      "  \"mask_time_min_masks\": 2,\n",
      "  \"mask_time_min_space\": 1,\n",
      "  \"mask_time_other\": 0.0,\n",
      "  \"mask_time_prob\": 0.05,\n",
      "  \"mask_time_selection\": \"static\",\n",
      "  \"model_type\": \"wav2vec2\",\n",
      "  \"num_adapter_layers\": 3,\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_codevector_groups\": 2,\n",
      "  \"num_codevectors_per_group\": 320,\n",
      "  \"num_conv_pos_embedding_groups\": 16,\n",
      "  \"num_conv_pos_embeddings\": 128,\n",
      "  \"num_feat_extract_layers\": 7,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"num_negatives\": 100,\n",
      "  \"output_hidden_size\": 1024,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"proj_codevector_dim\": 768,\n",
      "  \"tdnn_dilation\": [\n",
      "    1,\n",
      "    2,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"tdnn_dim\": [\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    512,\n",
      "    1500\n",
      "  ],\n",
      "  \"tdnn_kernel\": [\n",
      "    5,\n",
      "    3,\n",
      "    3,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.19.4\",\n",
      "  \"use_weighted_layer_sum\": false,\n",
      "  \"vocab_size\": 111,\n",
      "  \"xvector_output_dim\": 512\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/wav2vec2-large-xlsr-53/resolve/main/pytorch_model.bin from cache at C:\\Users\\AI_server/.cache\\huggingface\\transformers\\5d2a20b45a1689a376ec4a6282b9d9be42f931cdf8daf07c3668ba1070a059d9.622b46163a38532eae8ac5423b0481dfc0b9ea401af488b5141772bdff889079\n",
      "Some weights of the model checkpoint at facebook/wav2vec2-large-xlsr-53 were not used when initializing Wav2Vec2ForCTC: ['quantizer.weight_proj.bias', 'quantizer.weight_proj.weight', 'project_hid.bias', 'project_q.bias', 'quantizer.codevectors', 'project_q.weight', 'project_hid.weight']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-large-xlsr-53 and are newly initialized: ['lm_head.bias', 'lm_head.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Wav2Vec2ForCTC\n",
    "\n",
    "model = Wav2Vec2ForCTC.from_pretrained(\n",
    "    \"facebook/wav2vec2-large-xlsr-53\", \n",
    "    attention_dropout=0.1,\n",
    "    hidden_dropout=0.1,\n",
    "    feat_proj_dropout=0.0,\n",
    "    mask_time_prob=0.05,\n",
    "    layerdrop=0.1,\n",
    "    ctc_loss_reduction=\"mean\", \n",
    "    pad_token_id=processor.tokenizer.pad_token_id,\n",
    "    vocab_size=len(processor.tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaYmsSutuv26"
   },
   "source": [
    "XLSR-Wav2Vec2의 첫 번째 구성 요소는 원시 음성 신호에서 음향적으로 의미가 있지만 문맥적으로 독립적인 기능을 추출하는 데 사용되는 CNN 계층 스택으로 구성됩니다.  \n",
    "모델의 이 부분은 사전 교육 중에 이미 충분히 훈련되었으며 논문에 명시된 바와 같이 더 이상 미세 조정할 필요가 없습니다. 따라서 특징 추출 부분의 모든 파라미터에 대해 require_grad를 False로 설정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "5VX8z6PpuhqG"
   },
   "outputs": [],
   "source": [
    "model.freeze_feature_extractor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wAfoHUk9vGxd"
   },
   "source": [
    "메모리를 절약하기 위해 그라데이션 체크포인팅을 활성화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "wZm6in_2vAIN"
   },
   "outputs": [],
   "source": [
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-aJNQplvQgn"
   },
   "source": [
    "## TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "-LuuwoeMvOnV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "  # output_dir=\"/content/gdrive/MyDrive/wav2vec2-large-xlsr-ko-demo\",\n",
    "  output_dir=\"./wav2vec2-large-xlsr-ko-demo\",\n",
    "  group_by_length=True,\n",
    "  # per_device_train_batch_size=16,\n",
    "  gradient_accumulation_steps=2,\n",
    "  evaluation_strategy=\"steps\",\n",
    "  num_train_epochs=80,\n",
    "  fp16=True,\n",
    "  save_steps=100,\n",
    "  eval_steps=100,\n",
    "  logging_steps=10,\n",
    "  learning_rate=3e-4,\n",
    "  warmup_steps=500,\n",
    "  save_total_limit=2,\n",
    "#   auto_find_batch_size=True, # need -> pip install accelerate\n",
    "  load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "6vhFC0BdvcOu"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "ds_size = len(augmented_data)\n",
    "train_size = int(ds_size*0.8)\n",
    "val_size = ds_size - train_size\n",
    "train_ds, val_ds = random_split(augmented_data,[train_size,val_size])\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    data_collator=data_collator,\n",
    "    args=training_args,\n",
    "    compute_metrics=compute_metrics,\n",
    "    train_dataset=train_ds,\n",
    "    eval_dataset=val_ds,\n",
    "    tokenizer=processor.feature_extractor,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aHGNj1NSvsFk"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "a-rJ8fokvjJb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AI_server\\Anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3200\n",
      "  Num Epochs = 80\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 2\n",
      "  Total optimization steps = 16000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9570' max='16000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9570/16000 2:31:45 < 1:41:58, 1.05 it/s, Epoch 47.84/80]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Wer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>5.572800</td>\n",
       "      <td>5.400629</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.309100</td>\n",
       "      <td>3.387674</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.261600</td>\n",
       "      <td>3.408355</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.198900</td>\n",
       "      <td>3.433145</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.094700</td>\n",
       "      <td>3.183763</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.047600</td>\n",
       "      <td>3.110659</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>2.961600</td>\n",
       "      <td>3.035182</td>\n",
       "      <td>0.997554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.745700</td>\n",
       "      <td>2.687272</td>\n",
       "      <td>0.929305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.166200</td>\n",
       "      <td>2.064660</td>\n",
       "      <td>1.039139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.735500</td>\n",
       "      <td>1.487775</td>\n",
       "      <td>1.011497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.369200</td>\n",
       "      <td>1.059518</td>\n",
       "      <td>0.877935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.219300</td>\n",
       "      <td>0.783057</td>\n",
       "      <td>0.803327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.056200</td>\n",
       "      <td>0.538479</td>\n",
       "      <td>0.802838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.996400</td>\n",
       "      <td>0.453584</td>\n",
       "      <td>0.593933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.879900</td>\n",
       "      <td>0.387330</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.756300</td>\n",
       "      <td>0.335827</td>\n",
       "      <td>0.442270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.652500</td>\n",
       "      <td>0.270393</td>\n",
       "      <td>0.550881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.646200</td>\n",
       "      <td>0.240649</td>\n",
       "      <td>0.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.594800</td>\n",
       "      <td>0.209735</td>\n",
       "      <td>0.543297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.549500</td>\n",
       "      <td>0.177429</td>\n",
       "      <td>0.439824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.162553</td>\n",
       "      <td>0.469178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.514900</td>\n",
       "      <td>0.141625</td>\n",
       "      <td>0.416096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.462900</td>\n",
       "      <td>0.123125</td>\n",
       "      <td>0.365215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.485900</td>\n",
       "      <td>0.115015</td>\n",
       "      <td>0.424658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.379800</td>\n",
       "      <td>0.110319</td>\n",
       "      <td>0.411204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.099976</td>\n",
       "      <td>0.383072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.409400</td>\n",
       "      <td>0.104015</td>\n",
       "      <td>0.391145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.422300</td>\n",
       "      <td>0.094109</td>\n",
       "      <td>0.350049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.338900</td>\n",
       "      <td>0.089112</td>\n",
       "      <td>0.294521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.084134</td>\n",
       "      <td>0.305528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.345300</td>\n",
       "      <td>0.076512</td>\n",
       "      <td>0.327544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.292800</td>\n",
       "      <td>0.067888</td>\n",
       "      <td>0.329990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.217710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.335500</td>\n",
       "      <td>0.053513</td>\n",
       "      <td>0.276908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.332900</td>\n",
       "      <td>0.053231</td>\n",
       "      <td>0.272016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.334200</td>\n",
       "      <td>0.061760</td>\n",
       "      <td>0.355920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.288600</td>\n",
       "      <td>0.053776</td>\n",
       "      <td>0.237769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.287200</td>\n",
       "      <td>0.058414</td>\n",
       "      <td>0.348826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.046106</td>\n",
       "      <td>0.331458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.266800</td>\n",
       "      <td>0.056698</td>\n",
       "      <td>0.344912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.262700</td>\n",
       "      <td>0.045284</td>\n",
       "      <td>0.267613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.046029</td>\n",
       "      <td>0.292319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.235600</td>\n",
       "      <td>0.045737</td>\n",
       "      <td>0.248288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.237600</td>\n",
       "      <td>0.033942</td>\n",
       "      <td>0.238748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.280400</td>\n",
       "      <td>0.035592</td>\n",
       "      <td>0.271526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.289400</td>\n",
       "      <td>0.038773</td>\n",
       "      <td>0.315068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.041380</td>\n",
       "      <td>0.252446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.041637</td>\n",
       "      <td>0.265656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.041155</td>\n",
       "      <td>0.267368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.247500</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>0.235078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.185500</td>\n",
       "      <td>0.030722</td>\n",
       "      <td>0.271771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>0.028194</td>\n",
       "      <td>0.237769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.027308</td>\n",
       "      <td>0.193004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.199100</td>\n",
       "      <td>0.025008</td>\n",
       "      <td>0.193982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.210800</td>\n",
       "      <td>0.027020</td>\n",
       "      <td>0.229452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.203300</td>\n",
       "      <td>0.025366</td>\n",
       "      <td>0.210127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.214000</td>\n",
       "      <td>0.026723</td>\n",
       "      <td>0.214041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.231100</td>\n",
       "      <td>0.023192</td>\n",
       "      <td>0.132583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.196200</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.106164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.023181</td>\n",
       "      <td>0.210372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.023140</td>\n",
       "      <td>0.229452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.163300</td>\n",
       "      <td>0.021968</td>\n",
       "      <td>0.207192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.023696</td>\n",
       "      <td>0.242906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.021514</td>\n",
       "      <td>0.274706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.125800</td>\n",
       "      <td>0.019611</td>\n",
       "      <td>0.206458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.017275</td>\n",
       "      <td>0.090998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>0.169300</td>\n",
       "      <td>0.022564</td>\n",
       "      <td>0.195939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.194716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.018459</td>\n",
       "      <td>0.125734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.140800</td>\n",
       "      <td>0.018933</td>\n",
       "      <td>0.278620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>0.122800</td>\n",
       "      <td>0.015555</td>\n",
       "      <td>0.192515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.015110</td>\n",
       "      <td>0.138943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>0.146600</td>\n",
       "      <td>0.014859</td>\n",
       "      <td>0.192025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.016354</td>\n",
       "      <td>0.190802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.129200</td>\n",
       "      <td>0.016901</td>\n",
       "      <td>0.215264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>0.139700</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.249755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.016307</td>\n",
       "      <td>0.247309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.016504</td>\n",
       "      <td>0.267368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>0.141800</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.248043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.137800</td>\n",
       "      <td>0.014158</td>\n",
       "      <td>0.215753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>0.155100</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>0.219667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>0.094400</td>\n",
       "      <td>0.013108</td>\n",
       "      <td>0.226761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>0.100700</td>\n",
       "      <td>0.009856</td>\n",
       "      <td>0.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.013902</td>\n",
       "      <td>0.217955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.091200</td>\n",
       "      <td>0.014726</td>\n",
       "      <td>0.236546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>0.264922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>0.240215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.011054</td>\n",
       "      <td>0.245841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>0.216243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.124200</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.230431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.011212</td>\n",
       "      <td>0.221869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>0.071300</td>\n",
       "      <td>0.013163</td>\n",
       "      <td>0.248288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.011712</td>\n",
       "      <td>0.268102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.010860</td>\n",
       "      <td>0.251468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.072000</td>\n",
       "      <td>0.010948</td>\n",
       "      <td>0.248288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-1900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-1900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-2900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-2900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3300\\config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-3900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-3900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4900\\pytorch_model.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-4900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-4400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-5900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-5900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6500\\preprocessor_config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-6900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-6600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-7900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-7900] due to args.save_total_limit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8400] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8600\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8600\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8600\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8600\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8500] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8700\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8700\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8700\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8700\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8600] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8800\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8800\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8800\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8800\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8700] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8900\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8900\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8900\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-8900\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8800] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9000\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9000\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9000\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9000\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-8900] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9100\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9100\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9100\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9100\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-9000] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9200\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9200\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9200\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9200\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-9100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9300\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9300\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9300\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9300\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-9200] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9400\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9400\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9400\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9400\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-9300] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 800\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9500\n",
      "Configuration saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9500\\config.json\n",
      "Model weights saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9500\\pytorch_model.bin\n",
      "Feature extractor saved in ./wav2vec2-large-xlsr-ko-demo\\checkpoint-9500\\preprocessor_config.json\n",
      "Deleting older checkpoint [wav2vec2-large-xlsr-ko-demo\\checkpoint-9400] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17380\\4032920361.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m         )\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1527\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1528\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1530\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    470\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 471\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    472\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\torch\\utils\\data\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    414\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0msample_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcumulative_sizes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_idx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_idx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2123\u001b[0m         \u001b[1;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2124\u001b[0m         return self._getitem(\n\u001b[1;32m-> 2125\u001b[1;33m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2126\u001b[0m         )\n\u001b[0;32m   2127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2108\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2109\u001b[0m         formatted_output = format_table(\n\u001b[1;32m-> 2110\u001b[1;33m             \u001b[0mpa_subtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2111\u001b[0m         )\n\u001b[0;32m   2112\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mformatted_output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\STT\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m_unnest\u001b[1;34m(py_dict)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;34m\"\"\"Return the first element of a batch (dict) as a row (dict)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FxpIR_X8w3Pq"
   },
   "source": [
    "CTC 손실을 사용하여 더 큰 데이터 세트에서 더 큰 모델을 미세 조정하려면 [여기서](https://github.com/huggingface/transformers/tree/master/examples/pytorch/speech-recognition#connectionist-temporal-classification-without-language-model-ctc-wo-lm) 공식 음성 인식 예를 살펴봐야 한다."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00.XLSR - Wav2Vec2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "STT",
   "language": "python",
   "name": "stt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "19631f30805cf65d5465564d75f0fe7c05dee5c1f7be198222dbe754da644e52"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
